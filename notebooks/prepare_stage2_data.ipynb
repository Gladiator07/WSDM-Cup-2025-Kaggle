{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from scipy.special import softmax\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hard_to_soft_labels(row, smoothing=0.03):\n",
    "    hard_labels = row[\"hard_labels\"]\n",
    "    num_classes = 2\n",
    "    one_hot = np.eye(num_classes)[hard_labels]\n",
    "    smooth_labels = one_hot * (1 - smoothing) + smoothing / num_classes\n",
    "    return smooth_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert stage 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106064, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>hard_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90bfd142157948aba01931726c888e7f</td>\n",
       "      <td>Fuji vs. Nikon, which is better?</td>\n",
       "      <td>Both Fuji and Nikon are popular camera brands ...</td>\n",
       "      <td>This is a subjective question and the answer d...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d   \n",
       "1  90bfd142157948aba01931726c888e7f   \n",
       "\n",
       "                                            prompt  \\\n",
       "0  What is the difference between OpenCL and CUDA?   \n",
       "1                 Fuji vs. Nikon, which is better?   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "1  Both Fuji and Nikon are popular camera brands ...   \n",
       "\n",
       "                                          response_b   winner     model_a  \\\n",
       "0  OpenCL and CUDA are both programming languages...  model_b  chatglm-6b   \n",
       "1  This is a subjective question and the answer d...  model_b   koala-13b   \n",
       "\n",
       "            model_b language  split     source  hard_labels  \n",
       "0         koala-13b  English  train  lmsys_33k            1  \n",
       "1  oasst-pythia-12b  English  train  lmsys_33k            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read stage 1 data\n",
    "df = pd.read_parquet(\"../data/train_combined_stage_1.parquet\")\n",
    "df[\"hard_labels\"] = df[\"winner\"].map({\"model_a\": 0, \"model_b\": 1})\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>hard_labels</th>\n",
       "      <th>soft_labels</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90bfd142157948aba01931726c888e7f</td>\n",
       "      <td>Fuji vs. Nikon, which is better?</td>\n",
       "      <td>Both Fuji and Nikon are popular camera brands ...</td>\n",
       "      <td>This is a subjective question and the answer d...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a7c5accc53e649a3bc6b2e41d962ebc4</td>\n",
       "      <td>How to build an arena for chatbots?</td>\n",
       "      <td>Building an arena for chatbots can be done by ...</td>\n",
       "      <td>Building an arena for chatbots is a great way ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adf27e819a3c494cb6e993f0c660e097</td>\n",
       "      <td>When is it today?</td>\n",
       "      <td>I'm sorry, I cannot determine the current date...</td>\n",
       "      <td>Today is February 23, 2023.</td>\n",
       "      <td>model_a</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0fc42c6f5f14f2aa5a89f71f8553730</td>\n",
       "      <td>Count from 1 to 10 with step = 3</td>\n",
       "      <td>1, 4, 7, 10\\n\\nCounting with a step of 3 means...</td>\n",
       "      <td>1, 4, 7, 10</td>\n",
       "      <td>model_a</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d   \n",
       "1  90bfd142157948aba01931726c888e7f   \n",
       "2  a7c5accc53e649a3bc6b2e41d962ebc4   \n",
       "3  adf27e819a3c494cb6e993f0c660e097   \n",
       "4  c0fc42c6f5f14f2aa5a89f71f8553730   \n",
       "\n",
       "                                            prompt  \\\n",
       "0  What is the difference between OpenCL and CUDA?   \n",
       "1                 Fuji vs. Nikon, which is better?   \n",
       "2              How to build an arena for chatbots?   \n",
       "3                                When is it today?   \n",
       "4                 Count from 1 to 10 with step = 3   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "1  Both Fuji and Nikon are popular camera brands ...   \n",
       "2  Building an arena for chatbots can be done by ...   \n",
       "3  I'm sorry, I cannot determine the current date...   \n",
       "4  1, 4, 7, 10\\n\\nCounting with a step of 3 means...   \n",
       "\n",
       "                                          response_b   winner     model_a  \\\n",
       "0  OpenCL and CUDA are both programming languages...  model_b  chatglm-6b   \n",
       "1  This is a subjective question and the answer d...  model_b   koala-13b   \n",
       "2  Building an arena for chatbots is a great way ...  model_b  vicuna-13b   \n",
       "3                        Today is February 23, 2023.  model_a  vicuna-13b   \n",
       "4                                        1, 4, 7, 10  model_a  vicuna-13b   \n",
       "\n",
       "            model_b language  split     source  hard_labels     soft_labels  \\\n",
       "0         koala-13b  English  train  lmsys_33k            1  [0.015, 0.985]   \n",
       "1  oasst-pythia-12b  English  train  lmsys_33k            1  [0.015, 0.985]   \n",
       "2  oasst-pythia-12b  English  train  lmsys_33k            1  [0.015, 0.985]   \n",
       "3         koala-13b  English  train  lmsys_33k            0  [0.985, 0.015]   \n",
       "4         koala-13b  English  train  lmsys_33k            0  [0.985, 0.015]   \n",
       "\n",
       "           logits  \n",
       "0  [0.015, 0.985]  \n",
       "1  [0.015, 0.985]  \n",
       "2  [0.015, 0.985]  \n",
       "3  [0.985, 0.015]  \n",
       "4  [0.985, 0.015]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"soft_labels\"] = df.apply(convert_hard_to_soft_labels, axis=1)\n",
    "df[\"logits\"] = df[\"soft_labels\"].copy(deep=True) # keep the dummy column for consistency\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORPO DPO Mix dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/atharva/.cache/huggingface/datasets/mlabonne___parquet/mlabonne--orpo-dpo-mix-40k-flat-5250468d649a27bf/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'chosen', 'rejected', 'prompt', 'system', 'question'],\n",
       "    num_rows: 44245\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"mlabonne/orpo-dpo-mix-40k-flat\", split=\"train\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>hard_labels</th>\n",
       "      <th>soft_labels</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The setting is an otherworldly, yet eerily fam...</td>\n",
       "      <td>As you step onto the teleportation platform, t...</td>\n",
       "      <td>As you step onto the teleportation platform, t...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How many colors are traditionally recognized i...</td>\n",
       "      <td>Traditionally, a visible spectrum or optical r...</td>\n",
       "      <td>Traditionally, a visible spectrum or optical r...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>In a basket, there are 20 oranges, 60 apples, ...</td>\n",
       "      <td>First let's start by identifying the number of...</td>\n",
       "      <td>First let's start by identifying the number of...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which famous physicist developed the theory of...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>model_b</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Find 40 * 865. Exclude words; show only the math.</td>\n",
       "      <td>34,600\\n\\n40 x 865 = 34,600 \\n\\nNote: The resp...</td>\n",
       "      <td>40 * 865 = 34600</td>\n",
       "      <td>model_b</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44240</th>\n",
       "      <td>44240</td>\n",
       "      <td>Is it true that Mount Everest is the tallest m...</td>\n",
       "      <td>While Mount Everest is the highest peak above ...</td>\n",
       "      <td>Yes, it is true that Mount Everest is the tall...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44241</th>\n",
       "      <td>44241</td>\n",
       "      <td>Can you physically manipulate objects in your ...</td>\n",
       "      <td>Yes, I can physically manipulate objects in my...</td>\n",
       "      <td>No, I cannot physically manipulate objects in ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44242</th>\n",
       "      <td>44242</td>\n",
       "      <td>How long would it take you to drive to the nea...</td>\n",
       "      <td>It would take me approximately 15 minutes to d...</td>\n",
       "      <td>I'm an AI and don't have a physical presence, ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44243</th>\n",
       "      <td>44243</td>\n",
       "      <td>Does the color of nasal secretion indicate the...</td>\n",
       "      <td>No, the color of nasal secretion does not nece...</td>\n",
       "      <td>No, the color of nasal secretion or sputum (cl...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44244</th>\n",
       "      <td>44244</td>\n",
       "      <td>Can you differentiate between different textur...</td>\n",
       "      <td>Yes, humans can differentiate between differen...</td>\n",
       "      <td>Yes, I can differentiate between different tex...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>orpo_dpo_mix_40k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44245 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                             prompt  \\\n",
       "0          0  The setting is an otherworldly, yet eerily fam...   \n",
       "1          1  How many colors are traditionally recognized i...   \n",
       "2          2  In a basket, there are 20 oranges, 60 apples, ...   \n",
       "3          3  Which famous physicist developed the theory of...   \n",
       "4          4  Find 40 * 865. Exclude words; show only the math.   \n",
       "...      ...                                                ...   \n",
       "44240  44240  Is it true that Mount Everest is the tallest m...   \n",
       "44241  44241  Can you physically manipulate objects in your ...   \n",
       "44242  44242  How long would it take you to drive to the nea...   \n",
       "44243  44243  Does the color of nasal secretion indicate the...   \n",
       "44244  44244  Can you differentiate between different textur...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      As you step onto the teleportation platform, t...   \n",
       "1      Traditionally, a visible spectrum or optical r...   \n",
       "2      First let's start by identifying the number of...   \n",
       "3                                        Albert Einstein   \n",
       "4      34,600\\n\\n40 x 865 = 34,600 \\n\\nNote: The resp...   \n",
       "...                                                  ...   \n",
       "44240  While Mount Everest is the highest peak above ...   \n",
       "44241  Yes, I can physically manipulate objects in my...   \n",
       "44242  It would take me approximately 15 minutes to d...   \n",
       "44243  No, the color of nasal secretion does not nece...   \n",
       "44244  Yes, humans can differentiate between differen...   \n",
       "\n",
       "                                              response_b   winner  model_a  \\\n",
       "0      As you step onto the teleportation platform, t...  model_a  unknown   \n",
       "1      Traditionally, a visible spectrum or optical r...  model_b  unknown   \n",
       "2      First let's start by identifying the number of...  model_b  unknown   \n",
       "3                                        Albert Einstein  model_b  unknown   \n",
       "4                                       40 * 865 = 34600  model_b  unknown   \n",
       "...                                                  ...      ...      ...   \n",
       "44240  Yes, it is true that Mount Everest is the tall...  model_a  unknown   \n",
       "44241  No, I cannot physically manipulate objects in ...  model_b  unknown   \n",
       "44242  I'm an AI and don't have a physical presence, ...  model_b  unknown   \n",
       "44243  No, the color of nasal secretion or sputum (cl...  model_b  unknown   \n",
       "44244  Yes, I can differentiate between different tex...  model_b  unknown   \n",
       "\n",
       "       model_b language  split            source  hard_labels     soft_labels  \\\n",
       "0      unknown  English  train  orpo_dpo_mix_40k            0  [0.985, 0.015]   \n",
       "1      unknown  English  train  orpo_dpo_mix_40k            1  [0.015, 0.985]   \n",
       "2      unknown  English  train  orpo_dpo_mix_40k            1  [0.015, 0.985]   \n",
       "3      unknown  English  train  orpo_dpo_mix_40k            1  [0.015, 0.985]   \n",
       "4      unknown  English  train  orpo_dpo_mix_40k            1  [0.015, 0.985]   \n",
       "...        ...      ...    ...               ...          ...             ...   \n",
       "44240  unknown  English  train  orpo_dpo_mix_40k            0  [0.985, 0.015]   \n",
       "44241  unknown  English  train  orpo_dpo_mix_40k            1  [0.015, 0.985]   \n",
       "44242  unknown  English  train  orpo_dpo_mix_40k            1  [0.015, 0.985]   \n",
       "44243  unknown  English  train  orpo_dpo_mix_40k            1  [0.015, 0.985]   \n",
       "44244  unknown  English  train  orpo_dpo_mix_40k            1  [0.015, 0.985]   \n",
       "\n",
       "               logits  \n",
       "0      [0.985, 0.015]  \n",
       "1      [0.015, 0.985]  \n",
       "2      [0.015, 0.985]  \n",
       "3      [0.015, 0.985]  \n",
       "4      [0.015, 0.985]  \n",
       "...               ...  \n",
       "44240  [0.985, 0.015]  \n",
       "44241  [0.015, 0.985]  \n",
       "44242  [0.015, 0.985]  \n",
       "44243  [0.015, 0.985]  \n",
       "44244  [0.015, 0.985]  \n",
       "\n",
       "[44245 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_mix_df = []\n",
    "for i, d in enumerate(ds):\n",
    "    should_swap = np.random.random() > 0.5\n",
    "    if should_swap:\n",
    "        response_a = d[\"rejected\"]\n",
    "        response_b = d[\"chosen\"]\n",
    "        winner = \"model_b\"\n",
    "    else:\n",
    "        response_a = d[\"chosen\"]\n",
    "        response_b = d[\"rejected\"]\n",
    "        winner = \"model_a\"\n",
    "    dpo_mix_df.append({\n",
    "        \"id\": str(i),\n",
    "        \"prompt\": d[\"prompt\"],\n",
    "        \"response_a\": response_a,\n",
    "        \"response_b\": response_b,\n",
    "        \"winner\": winner,\n",
    "        \"model_a\": \"unknown\",\n",
    "        \"model_b\": \"unknown\",\n",
    "        \"language\": \"English\",\n",
    "        \"split\": \"train\",\n",
    "        \"source\": \"orpo_dpo_mix_40k\",\n",
    "    })\n",
    "\n",
    "dpo_mix_df = pd.DataFrame(dpo_mix_df)\n",
    "dpo_mix_df[\"hard_labels\"] = dpo_mix_df[\"winner\"].map({\"model_a\": 0, \"model_b\": 1})\n",
    "dpo_mix_df[\"soft_labels\"] = dpo_mix_df.apply(convert_hard_to_soft_labels, axis=1)\n",
    "dpo_mix_df[\"logits\"] = dpo_mix_df[\"soft_labels\"].copy(deep=True) # keep the dummy column for consistency\n",
    "dpo_mix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lmsys 110k pseudo-labelled ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lmsys_data(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df.drop(columns=[\"winner\"], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125878, 8)\n",
      "(125878, 8)\n",
      "(125878, 8)\n",
      "(125878, 8)\n"
     ]
    }
   ],
   "source": [
    "lmsys_gemma2_df = load_lmsys_data(\"../data/lmsys1m_125k_pseudo_label_gemma2stage1.parquet\")\n",
    "lmsys_gemma2_tta_df = load_lmsys_data(\"../data/lmsys1m_125k_pseudo_label_gemma2stage1_tta.parquet\")\n",
    "lmsys_llama3_df = load_lmsys_data(\"../data/lmsys1m_125k_pseudo_label_llama3stage1.parquet\")\n",
    "lmsys_llama3_tta_df = load_lmsys_data(\"../data/lmsys1m_125k_pseudo_label_llama3stage1_tta.parquet\")\n",
    "print(lmsys_gemma2_df.shape)\n",
    "print(lmsys_llama3_df.shape)\n",
    "print(lmsys_gemma2_tta_df.shape)\n",
    "print(lmsys_llama3_tta_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>logits</th>\n",
       "      <th>logits_tta</th>\n",
       "      <th>logits_gemma2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8b8a298a65a4169963967da44c5b05b</td>\n",
       "      <td>crie uma programa em html, js, cs,  que solici...</td>\n",
       "      <td>Aqui está um exemplo de como você pode criar u...</td>\n",
       "      <td>Aqui está um programa em HTML, JavaScript e CS...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[0.26953125, 0.78515625]</td>\n",
       "      <td>[0.353515625, 0.84765625]</td>\n",
       "      <td>[0.303125, 0.81015625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dfbc4eeb6624cdd929cabeeb6f99d26</td>\n",
       "      <td>Erzähle mir eine lustige aber lehrreiche Kurzg...</td>\n",
       "      <td>### Eine lustige und lehrreiche Kurzgeschichte...</td>\n",
       "      <td>Es war einmal ein junges, sprechendes Ferkel n...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>German</td>\n",
       "      <td>[0.74609375, 0.6796875]</td>\n",
       "      <td>[0.25390625, 1.046875]</td>\n",
       "      <td>[0.54921875, 0.8265625]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d8b8a298a65a4169963967da44c5b05b   \n",
       "1  6dfbc4eeb6624cdd929cabeeb6f99d26   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  crie uma programa em html, js, cs,  que solici...   \n",
       "1  Erzähle mir eine lustige aber lehrreiche Kurzg...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  Aqui está um exemplo de como você pode criar u...   \n",
       "1  ### Eine lustige und lehrreiche Kurzgeschichte...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  Aqui está um programa em HTML, JavaScript e CS...   \n",
       "1  Es war einmal ein junges, sprechendes Ferkel n...   \n",
       "\n",
       "                               model_a                               model_b  \\\n",
       "0  meta-llama/Meta-Llama-3-8B-Instruct  mistralai/Mistral-Nemo-Instruct-2407   \n",
       "1             Qwen/Qwen2.5-3B-Instruct                            vicuna-13b   \n",
       "\n",
       "     language                    logits                 logits_tta  \\\n",
       "0  Portuguese  [0.26953125, 0.78515625]  [0.353515625, 0.84765625]   \n",
       "1      German   [0.74609375, 0.6796875]     [0.25390625, 1.046875]   \n",
       "\n",
       "             logits_gemma2  \n",
       "0   [0.303125, 0.81015625]  \n",
       "1  [0.54921875, 0.8265625]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>logits</th>\n",
       "      <th>logits_tta</th>\n",
       "      <th>logits_llama3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8b8a298a65a4169963967da44c5b05b</td>\n",
       "      <td>crie uma programa em html, js, cs,  que solici...</td>\n",
       "      <td>Aqui está um exemplo de como você pode criar u...</td>\n",
       "      <td>Aqui está um programa em HTML, JavaScript e CS...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[0.41796875, 0.67578125]</td>\n",
       "      <td>[0.55859375, 0.482421875]</td>\n",
       "      <td>[0.48828125, 0.5791015625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c65335723f7f452187c3a1db28017e41</td>\n",
       "      <td>Gere uma lista com 200 frases mais utilizadas ...</td>\n",
       "      <td>Aqui está a lista de 200 frases mais utilizada...</td>\n",
       "      <td>1. \"Hello, welcome to [Airport Name]!\"\\n   \"Ol...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[1.1875, 0.1572265625]</td>\n",
       "      <td>[1.1171875, 0.07568359375]</td>\n",
       "      <td>[1.15234375, 0.116455078125]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d8b8a298a65a4169963967da44c5b05b   \n",
       "1  c65335723f7f452187c3a1db28017e41   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  crie uma programa em html, js, cs,  que solici...   \n",
       "1  Gere uma lista com 200 frases mais utilizadas ...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  Aqui está um exemplo de como você pode criar u...   \n",
       "1  Aqui está a lista de 200 frases mais utilizada...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  Aqui está um programa em HTML, JavaScript e CS...   \n",
       "1  1. \"Hello, welcome to [Airport Name]!\"\\n   \"Ol...   \n",
       "\n",
       "                               model_a                               model_b  \\\n",
       "0  meta-llama/Meta-Llama-3-8B-Instruct  mistralai/Mistral-Nemo-Instruct-2407   \n",
       "1  meta-llama/Meta-Llama-3-8B-Instruct  mistralai/Mistral-Nemo-Instruct-2407   \n",
       "\n",
       "     language                    logits                  logits_tta  \\\n",
       "0  Portuguese  [0.41796875, 0.67578125]   [0.55859375, 0.482421875]   \n",
       "1  Portuguese    [1.1875, 0.1572265625]  [1.1171875, 0.07568359375]   \n",
       "\n",
       "                  logits_llama3  \n",
       "0    [0.48828125, 0.5791015625]  \n",
       "1  [1.15234375, 0.116455078125]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_to_merge = [col for col in lmsys_gemma2_tta_df.columns if col not in [\"logits\"]]\n",
    "gemma_df = pd.merge(lmsys_gemma2_df, lmsys_gemma2_tta_df, on=cols_to_merge, suffixes=(\"\", \"_tta\"))\n",
    "w = 0.6\n",
    "gemma_df[\"logits_gemma2\"] = (w * np.array(gemma_df[\"logits\"]) + (1- w) * np.array(gemma_df[\"logits_tta\"])).tolist()\n",
    "\n",
    "llama_df = pd.merge(lmsys_llama3_df, lmsys_llama3_tta_df, on=cols_to_merge, suffixes=(\"\", \"_tta\"))\n",
    "w = 0.5\n",
    "llama_df[\"logits_llama3\"] = (w * np.array(llama_df[\"logits\"]) + (1- w) * np.array(llama_df[\"logits_tta\"])).tolist()\n",
    "display(gemma_df.head(2))\n",
    "display(llama_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>logits_gemma2</th>\n",
       "      <th>logits_llama3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8b8a298a65a4169963967da44c5b05b</td>\n",
       "      <td>crie uma programa em html, js, cs,  que solici...</td>\n",
       "      <td>Aqui está um exemplo de como você pode criar u...</td>\n",
       "      <td>Aqui está um programa em HTML, JavaScript e CS...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[0.303125, 0.81015625]</td>\n",
       "      <td>[0.48828125, 0.5791015625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dfbc4eeb6624cdd929cabeeb6f99d26</td>\n",
       "      <td>Erzähle mir eine lustige aber lehrreiche Kurzg...</td>\n",
       "      <td>### Eine lustige und lehrreiche Kurzgeschichte...</td>\n",
       "      <td>Es war einmal ein junges, sprechendes Ferkel n...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>German</td>\n",
       "      <td>[0.54921875, 0.8265625]</td>\n",
       "      <td>[0.6328125, 0.705078125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7e67947c57c643be8d2d4439d97b2519</td>\n",
       "      <td>Ik wil een recept voor baklava</td>\n",
       "      <td>Hier is een basisrecept voor baklava, een klas...</td>\n",
       "      <td>Baklava is een traditionele gestoomde taart ui...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>[-0.390625, 1.6484375]</td>\n",
       "      <td>[-0.6748046875, 2.34375]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d8b8a298a65a4169963967da44c5b05b   \n",
       "1  6dfbc4eeb6624cdd929cabeeb6f99d26   \n",
       "2  7e67947c57c643be8d2d4439d97b2519   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  crie uma programa em html, js, cs,  que solici...   \n",
       "1  Erzähle mir eine lustige aber lehrreiche Kurzg...   \n",
       "2                     Ik wil een recept voor baklava   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  Aqui está um exemplo de como você pode criar u...   \n",
       "1  ### Eine lustige und lehrreiche Kurzgeschichte...   \n",
       "2  Hier is een basisrecept voor baklava, een klas...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  Aqui está um programa em HTML, JavaScript e CS...   \n",
       "1  Es war einmal ein junges, sprechendes Ferkel n...   \n",
       "2  Baklava is een traditionele gestoomde taart ui...   \n",
       "\n",
       "                               model_a                               model_b  \\\n",
       "0  meta-llama/Meta-Llama-3-8B-Instruct  mistralai/Mistral-Nemo-Instruct-2407   \n",
       "1             Qwen/Qwen2.5-3B-Instruct                            vicuna-13b   \n",
       "2             Qwen/Qwen2.5-3B-Instruct                            vicuna-13b   \n",
       "\n",
       "     language            logits_gemma2               logits_llama3  \n",
       "0  Portuguese   [0.303125, 0.81015625]  [0.48828125, 0.5791015625]  \n",
       "1      German  [0.54921875, 0.8265625]    [0.6328125, 0.705078125]  \n",
       "2       Dutch   [-0.390625, 1.6484375]    [-0.6748046875, 2.34375]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of common columns (everything except logits)\n",
    "common_columns = ['id', 'prompt', 'response_a', 'response_b', 'model_a', 'model_b', 'language']\n",
    "\n",
    "lmsys_df = pd.merge(\n",
    "    gemma_df[common_columns + ['logits_gemma2']], \n",
    "    llama_df[common_columns + ['logits_llama3']], \n",
    "    on=common_columns\n",
    ")\n",
    "lmsys_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>logits_gemma2</th>\n",
       "      <th>logits_llama3</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8b8a298a65a4169963967da44c5b05b</td>\n",
       "      <td>crie uma programa em html, js, cs,  que solici...</td>\n",
       "      <td>Aqui está um exemplo de como você pode criar u...</td>\n",
       "      <td>Aqui está um programa em HTML, JavaScript e CS...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[0.303125, 0.81015625]</td>\n",
       "      <td>[0.48828125, 0.5791015625]</td>\n",
       "      <td>[0.34241515624999996, 0.7611264453125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dfbc4eeb6624cdd929cabeeb6f99d26</td>\n",
       "      <td>Erzähle mir eine lustige aber lehrreiche Kurzg...</td>\n",
       "      <td>### Eine lustige und lehrreiche Kurzgeschichte...</td>\n",
       "      <td>Es war einmal ein junges, sprechendes Ferkel n...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>German</td>\n",
       "      <td>[0.54921875, 0.8265625]</td>\n",
       "      <td>[0.6328125, 0.705078125]</td>\n",
       "      <td>[0.56695734375, 0.800783515625]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d8b8a298a65a4169963967da44c5b05b   \n",
       "1  6dfbc4eeb6624cdd929cabeeb6f99d26   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  crie uma programa em html, js, cs,  que solici...   \n",
       "1  Erzähle mir eine lustige aber lehrreiche Kurzg...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  Aqui está um exemplo de como você pode criar u...   \n",
       "1  ### Eine lustige und lehrreiche Kurzgeschichte...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  Aqui está um programa em HTML, JavaScript e CS...   \n",
       "1  Es war einmal ein junges, sprechendes Ferkel n...   \n",
       "\n",
       "                               model_a                               model_b  \\\n",
       "0  meta-llama/Meta-Llama-3-8B-Instruct  mistralai/Mistral-Nemo-Instruct-2407   \n",
       "1             Qwen/Qwen2.5-3B-Instruct                            vicuna-13b   \n",
       "\n",
       "     language            logits_gemma2               logits_llama3  \\\n",
       "0  Portuguese   [0.303125, 0.81015625]  [0.48828125, 0.5791015625]   \n",
       "1      German  [0.54921875, 0.8265625]    [0.6328125, 0.705078125]   \n",
       "\n",
       "                                   logits  \n",
       "0  [0.34241515624999996, 0.7611264453125]  \n",
       "1         [0.56695734375, 0.800783515625]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weighted ensemble of logits\n",
    "#0.8 for gemma2 and 0.2 for llama3 (calculated on validation set)\n",
    "w = 0.7878\n",
    "lmsys_df['logits'] = (w * np.array(lmsys_df[\"logits_gemma2\"].tolist()) + (1-w) * np.array(lmsys_df[\"logits_llama3\"].tolist())).tolist()\n",
    "lmsys_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>logits</th>\n",
       "      <th>hard_labels</th>\n",
       "      <th>winner</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>soft_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8b8a298a65a4169963967da44c5b05b</td>\n",
       "      <td>crie uma programa em html, js, cs,  que solici...</td>\n",
       "      <td>Aqui está um exemplo de como você pode criar u...</td>\n",
       "      <td>Aqui está um programa em HTML, JavaScript e CS...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[0.34241515624999996, 0.7611264453125]</td>\n",
       "      <td>1</td>\n",
       "      <td>model_b</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_125k_multilingual_gemma2_llama3_ensemble...</td>\n",
       "      <td>[0.3968251684318443, 0.6031748315681557]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dfbc4eeb6624cdd929cabeeb6f99d26</td>\n",
       "      <td>Erzähle mir eine lustige aber lehrreiche Kurzg...</td>\n",
       "      <td>### Eine lustige und lehrreiche Kurzgeschichte...</td>\n",
       "      <td>Es war einmal ein junges, sprechendes Ferkel n...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>German</td>\n",
       "      <td>[0.56695734375, 0.800783515625]</td>\n",
       "      <td>1</td>\n",
       "      <td>model_b</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_125k_multilingual_gemma2_llama3_ensemble...</td>\n",
       "      <td>[0.44180834989076534, 0.5581916501092347]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d8b8a298a65a4169963967da44c5b05b   \n",
       "1  6dfbc4eeb6624cdd929cabeeb6f99d26   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  crie uma programa em html, js, cs,  que solici...   \n",
       "1  Erzähle mir eine lustige aber lehrreiche Kurzg...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  Aqui está um exemplo de como você pode criar u...   \n",
       "1  ### Eine lustige und lehrreiche Kurzgeschichte...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  Aqui está um programa em HTML, JavaScript e CS...   \n",
       "1  Es war einmal ein junges, sprechendes Ferkel n...   \n",
       "\n",
       "                               model_a                               model_b  \\\n",
       "0  meta-llama/Meta-Llama-3-8B-Instruct  mistralai/Mistral-Nemo-Instruct-2407   \n",
       "1             Qwen/Qwen2.5-3B-Instruct                            vicuna-13b   \n",
       "\n",
       "     language                                  logits  hard_labels   winner  \\\n",
       "0  Portuguese  [0.34241515624999996, 0.7611264453125]            1  model_b   \n",
       "1      German         [0.56695734375, 0.800783515625]            1  model_b   \n",
       "\n",
       "   split                                             source  \\\n",
       "0  train  lmsys_125k_multilingual_gemma2_llama3_ensemble...   \n",
       "1  train  lmsys_125k_multilingual_gemma2_llama3_ensemble...   \n",
       "\n",
       "                                 soft_labels  \n",
       "0   [0.3968251684318443, 0.6031748315681557]  \n",
       "1  [0.44180834989076534, 0.5581916501092347]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the logits_gemma2 and logits_llama3 columns\n",
    "lmsys_df = lmsys_df.drop(['logits_gemma2', 'logits_llama3'], axis=1)\n",
    "lmsys_df[\"hard_labels\"] = lmsys_df[\"logits\"].apply(lambda x: np.argmax(x, axis=-1))\n",
    "lmsys_df[\"winner\"] = lmsys_df[\"hard_labels\"].map({0: \"model_a\", 1: \"model_b\"})\n",
    "lmsys_df[\"split\"] = \"train\"\n",
    "lmsys_df[\"source\"] = \"lmsys_125k_multilingual_gemma2_llama3_ensemble_stage1\"\n",
    "lmsys_df[\"soft_labels\"] = lmsys_df[\"logits\"].apply(softmax, axis=-1)\n",
    "lmsys_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>hard_labels</th>\n",
       "      <th>soft_labels</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90bfd142157948aba01931726c888e7f</td>\n",
       "      <td>Fuji vs. Nikon, which is better?</td>\n",
       "      <td>Both Fuji and Nikon are popular camera brands ...</td>\n",
       "      <td>This is a subjective question and the answer d...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a7c5accc53e649a3bc6b2e41d962ebc4</td>\n",
       "      <td>How to build an arena for chatbots?</td>\n",
       "      <td>Building an arena for chatbots can be done by ...</td>\n",
       "      <td>Building an arena for chatbots is a great way ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "      <td>[0.015, 0.985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adf27e819a3c494cb6e993f0c660e097</td>\n",
       "      <td>When is it today?</td>\n",
       "      <td>I'm sorry, I cannot determine the current date...</td>\n",
       "      <td>Today is February 23, 2023.</td>\n",
       "      <td>model_a</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0fc42c6f5f14f2aa5a89f71f8553730</td>\n",
       "      <td>Count from 1 to 10 with step = 3</td>\n",
       "      <td>1, 4, 7, 10\\n\\nCounting with a step of 3 means...</td>\n",
       "      <td>1, 4, 7, 10</td>\n",
       "      <td>model_a</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "      <td>[0.985, 0.015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276182</th>\n",
       "      <td>646ef0b0fda143cdb89cd32ed18c940c</td>\n",
       "      <td>bom dia</td>\n",
       "      <td>Bom dia!</td>\n",
       "      <td></td>\n",
       "      <td>model_a</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>microsoft/Phi-3.5-mini-instruct</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_125k_multilingual_gemma2_llama3_ensemble...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.973595048493256, 0.026404951506744156]</td>\n",
       "      <td>[2.3919259375, -1.21551796875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276183</th>\n",
       "      <td>2a272049f63c4722b426a32eda916b57</td>\n",
       "      <td>测试</td>\n",
       "      <td>测试</td>\n",
       "      <td>你好。</td>\n",
       "      <td>model_b</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_125k_multilingual_gemma2_llama3_ensemble...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.28934563217230397, 0.7106543678276961]</td>\n",
       "      <td>[0.05055058593750002, 0.9491148437500001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276184</th>\n",
       "      <td>534e6da0e64244d4a44128f151ade350</td>\n",
       "      <td>今天</td>\n",
       "      <td>今天。</td>\n",
       "      <td>,</td>\n",
       "      <td>model_a</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_125k_multilingual_gemma2_llama3_ensemble...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8911540994648454, 0.10884590053515462]</td>\n",
       "      <td>[1.6360987500000002, -0.46648548828124997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276185</th>\n",
       "      <td>f4f9ee96a26b479a99e7ddc585685c15</td>\n",
       "      <td>سلام</td>\n",
       "      <td>سلام!</td>\n",
       "      <td>خوب</td>\n",
       "      <td>model_a</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>microsoft/Phi-3-mini-4k-instruct</td>\n",
       "      <td>Persian</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_125k_multilingual_gemma2_llama3_ensemble...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6113861613452167, 0.38861383865478316]</td>\n",
       "      <td>[0.684996328125, 0.231853701171875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276186</th>\n",
       "      <td>31a8c80814474ff9848d97a913c5e54f</td>\n",
       "      <td>嗯</td>\n",
       "      <td>​</td>\n",
       "      <td>😊</td>\n",
       "      <td>model_b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_125k_multilingual_gemma2_llama3_ensemble...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.17241949508761617, 0.8275805049123838]</td>\n",
       "      <td>[-0.29018533203124997, 1.278390625]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276187 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0       58210e39b3fd4441a2bd4a518bb44c2d   \n",
       "1       90bfd142157948aba01931726c888e7f   \n",
       "2       a7c5accc53e649a3bc6b2e41d962ebc4   \n",
       "3       adf27e819a3c494cb6e993f0c660e097   \n",
       "4       c0fc42c6f5f14f2aa5a89f71f8553730   \n",
       "...                                  ...   \n",
       "276182  646ef0b0fda143cdb89cd32ed18c940c   \n",
       "276183  2a272049f63c4722b426a32eda916b57   \n",
       "276184  534e6da0e64244d4a44128f151ade350   \n",
       "276185  f4f9ee96a26b479a99e7ddc585685c15   \n",
       "276186  31a8c80814474ff9848d97a913c5e54f   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0       What is the difference between OpenCL and CUDA?   \n",
       "1                      Fuji vs. Nikon, which is better?   \n",
       "2                   How to build an arena for chatbots?   \n",
       "3                                     When is it today?   \n",
       "4                      Count from 1 to 10 with step = 3   \n",
       "...                                                 ...   \n",
       "276182                                          bom dia   \n",
       "276183                                               测试   \n",
       "276184                                               今天   \n",
       "276185                                             سلام   \n",
       "276186                                                嗯   \n",
       "\n",
       "                                               response_a  \\\n",
       "0       OpenCL and CUDA are two different programming ...   \n",
       "1       Both Fuji and Nikon are popular camera brands ...   \n",
       "2       Building an arena for chatbots can be done by ...   \n",
       "3       I'm sorry, I cannot determine the current date...   \n",
       "4       1, 4, 7, 10\\n\\nCounting with a step of 3 means...   \n",
       "...                                                   ...   \n",
       "276182                                           Bom dia!   \n",
       "276183                                                 测试   \n",
       "276184                                                今天。   \n",
       "276185                                              سلام!   \n",
       "276186                                                  ​   \n",
       "\n",
       "                                               response_b   winner  \\\n",
       "0       OpenCL and CUDA are both programming languages...  model_b   \n",
       "1       This is a subjective question and the answer d...  model_b   \n",
       "2       Building an arena for chatbots is a great way ...  model_b   \n",
       "3                             Today is February 23, 2023.  model_a   \n",
       "4                                             1, 4, 7, 10  model_a   \n",
       "...                                                   ...      ...   \n",
       "276182                                                     model_a   \n",
       "276183                                                你好。  model_b   \n",
       "276184                                                  ,  model_a   \n",
       "276185                                                خوب  model_a   \n",
       "276186                                                  😊  model_b   \n",
       "\n",
       "                                    model_a  \\\n",
       "0                                chatglm-6b   \n",
       "1                                 koala-13b   \n",
       "2                                vicuna-13b   \n",
       "3                                vicuna-13b   \n",
       "4                                vicuna-13b   \n",
       "...                                     ...   \n",
       "276182  meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "276183                           alpaca-13b   \n",
       "276184     meta-llama/Llama-3.1-8B-Instruct   \n",
       "276185                           chatglm-6b   \n",
       "276186                           vicuna-13b   \n",
       "\n",
       "                                    model_b    language  split  \\\n",
       "0                                 koala-13b     English  train   \n",
       "1                          oasst-pythia-12b     English  train   \n",
       "2                          oasst-pythia-12b     English  train   \n",
       "3                                 koala-13b     English  train   \n",
       "4                                 koala-13b     English  train   \n",
       "...                                     ...         ...    ...   \n",
       "276182      microsoft/Phi-3.5-mini-instruct  Portuguese  train   \n",
       "276183    meta-llama/Llama-3.1-70B-Instruct     Chinese  train   \n",
       "276184                       fastchat-t5-3b    Japanese  train   \n",
       "276185     microsoft/Phi-3-mini-4k-instruct     Persian  train   \n",
       "276186  meta-llama/Meta-Llama-3-8B-Instruct     Chinese  train   \n",
       "\n",
       "                                                   source  hard_labels  \\\n",
       "0                                               lmsys_33k            1   \n",
       "1                                               lmsys_33k            1   \n",
       "2                                               lmsys_33k            1   \n",
       "3                                               lmsys_33k            0   \n",
       "4                                               lmsys_33k            0   \n",
       "...                                                   ...          ...   \n",
       "276182  lmsys_125k_multilingual_gemma2_llama3_ensemble...            0   \n",
       "276183  lmsys_125k_multilingual_gemma2_llama3_ensemble...            1   \n",
       "276184  lmsys_125k_multilingual_gemma2_llama3_ensemble...            0   \n",
       "276185  lmsys_125k_multilingual_gemma2_llama3_ensemble...            0   \n",
       "276186  lmsys_125k_multilingual_gemma2_llama3_ensemble...            1   \n",
       "\n",
       "                                      soft_labels  \\\n",
       "0                                  [0.015, 0.985]   \n",
       "1                                  [0.015, 0.985]   \n",
       "2                                  [0.015, 0.985]   \n",
       "3                                  [0.985, 0.015]   \n",
       "4                                  [0.985, 0.015]   \n",
       "...                                           ...   \n",
       "276182  [0.973595048493256, 0.026404951506744156]   \n",
       "276183  [0.28934563217230397, 0.7106543678276961]   \n",
       "276184  [0.8911540994648454, 0.10884590053515462]   \n",
       "276185  [0.6113861613452167, 0.38861383865478316]   \n",
       "276186  [0.17241949508761617, 0.8275805049123838]   \n",
       "\n",
       "                                            logits  \n",
       "0                                   [0.015, 0.985]  \n",
       "1                                   [0.015, 0.985]  \n",
       "2                                   [0.015, 0.985]  \n",
       "3                                   [0.985, 0.015]  \n",
       "4                                   [0.985, 0.015]  \n",
       "...                                            ...  \n",
       "276182              [2.3919259375, -1.21551796875]  \n",
       "276183   [0.05055058593750002, 0.9491148437500001]  \n",
       "276184  [1.6360987500000002, -0.46648548828124997]  \n",
       "276185         [0.684996328125, 0.231853701171875]  \n",
       "276186         [-0.29018533203124997, 1.278390625]  \n",
       "\n",
       "[276187 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([df, dpo_mix_df, lmsys_df], ignore_index=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'unknown': 88490,\n",
       "         'vicuna-13b': 59605,\n",
       "         'alpaca-13b': 14114,\n",
       "         'koala-13b': 10525,\n",
       "         'chatglm-6b': 9246,\n",
       "         'meta-llama/Meta-Llama-3-8B-Instruct': 8633,\n",
       "         'mistralai/Mistral-7B-Instruct-v0.3': 8416,\n",
       "         'claude-1': 7944,\n",
       "         'allenai/Llama-3.1-Tulu-3-8B': 7103,\n",
       "         'Qwen/Qwen2.5-7B-Instruct': 7086,\n",
       "         'meta-llama/Llama-3.1-8B-Instruct': 7041,\n",
       "         'Qwen/Qwen2-1.5B-Instruct': 7037,\n",
       "         'microsoft/Phi-3-mini-4k-instruct': 6999,\n",
       "         'google/gemma-2-9b-it': 6993,\n",
       "         'Qwen/Qwen2.5-14B-Instruct-AWQ': 6971,\n",
       "         'mistralai/Mistral-7B-Instruct-v0.2': 6967,\n",
       "         'Nexusflow/Starling-LM-7B-beta': 6941,\n",
       "         'google/gemma-2-2b-it': 6917,\n",
       "         'meta-llama/Llama-3.2-3B-Instruct': 6905,\n",
       "         'Qwen/Qwen2.5-3B-Instruct': 6800,\n",
       "         'Qwen/Qwen2-7B-Instruct': 6766,\n",
       "         'oasst-pythia-12b': 6453,\n",
       "         'gpt-4-1106-preview': 6080,\n",
       "         'llama-2-13b-chat': 6019,\n",
       "         'vicuna-33b': 5881,\n",
       "         'fastchat-t5-3b': 5256,\n",
       "         'llama-13b': 5127,\n",
       "         'gpt-3.5-turbo-0613': 4866,\n",
       "         'dolly-v2-12b': 4724,\n",
       "         'RWKV-4-Raven-14B': 4708,\n",
       "         'gpt-4-0613': 4306,\n",
       "         'vicuna-7b': 4268,\n",
       "         'claude-2.1': 3969,\n",
       "         'chatgpt-4o-latest-20240903': 3702,\n",
       "         'gemini-1.5-pro-002': 3587,\n",
       "         'palm-2': 3569,\n",
       "         'mistralai/Mistral-Nemo-Instruct-2407': 3562,\n",
       "         'mpt-7b-chat': 3529,\n",
       "         'stablelm-tuned-alpha-7b': 3514,\n",
       "         'claude-instant-1': 3454,\n",
       "         'claude-3-opus-20240229': 3413,\n",
       "         'gpt-3.5-turbo': 3347,\n",
       "         'yi-lightning-lite': 3328,\n",
       "         'gpt-4': 3239,\n",
       "         'qwen-max-0919': 3212,\n",
       "         'meta-llama/Llama-3.3-70B-Instruct': 3010,\n",
       "         'mistralai/Mixtral-8x7B-Instruct-v0.1': 2995,\n",
       "         'llama-3.1-405b-instruct-bf16': 2951,\n",
       "         'Qwen/Qwen2.5-72B-Instruct': 2927,\n",
       "         'gpt-4-0314': 2923,\n",
       "         '01-ai/Yi-1.5-34B-Chat': 2918,\n",
       "         'HuggingFaceH4/starchat2-15b-v0.1': 2909,\n",
       "         'gemini-1.5-flash-8b-001': 2863,\n",
       "         'grok-2-2024-08-13': 2806,\n",
       "         'wizardlm-13b': 2802,\n",
       "         'gemini-1.5-flash-002': 2686,\n",
       "         'qwen-plus-0828': 2658,\n",
       "         'guanaco-33b': 2556,\n",
       "         'claude-3-5-sonnet-20240620': 2536,\n",
       "         'mixtral-8x7b-instruct-v0.1': 2406,\n",
       "         'o1-mini': 2403,\n",
       "         'gemma-2-2b-it': 2391,\n",
       "         'claude-v1': 2379,\n",
       "         'gpt-4-0125-preview': 2375,\n",
       "         'o1-preview': 2366,\n",
       "         'gpt-3.5-turbo-1106': 2317,\n",
       "         'llama-2-70b-chat': 2315,\n",
       "         'internlm2_5-20b-chat': 2306,\n",
       "         'yi-lightning': 2280,\n",
       "         'mistral-medium': 2231,\n",
       "         'gemini-1.5-flash-8b-exp-0827': 2119,\n",
       "         'llama-3.2-1b-instruct': 2119,\n",
       "         'gpt4all-13b-snoozy': 2100,\n",
       "         'command-r-08-2024': 2013,\n",
       "         'command-r-plus-08-2024': 1996,\n",
       "         'mistral-large-2407': 1987,\n",
       "         'llama-3.2-3b-instruct': 1966,\n",
       "         'glm-4-plus': 1931,\n",
       "         'grok-2-mini-2024-08-13': 1858,\n",
       "         'qwen2.5-72b-instruct': 1845,\n",
       "         'llama-3.1-8b-instruct': 1784,\n",
       "         'claude-3-haiku-20240307': 1775,\n",
       "         'llama-3.1-70b-instruct': 1749,\n",
       "         'gpt-4o-mini-2024-07-18': 1747,\n",
       "         'gpt-4o-2024-08-06': 1745,\n",
       "         'claude-2.0': 1741,\n",
       "         'gpt-4o-2024-05-13': 1715,\n",
       "         'Qwen/Qwen2.5-Coder-32B-Instruct': 1695,\n",
       "         'llama-3.1-405b-instruct-fp8': 1679,\n",
       "         'llama-2-7b-chat': 1672,\n",
       "         'gemma-2-27b-it': 1659,\n",
       "         'meta-llama/Llama-3.1-70B-Instruct': 1657,\n",
       "         'deepseek-v2.5': 1636,\n",
       "         'zephyr-7b-beta': 1624,\n",
       "         'claude-instant-v1': 1520,\n",
       "         'reka-core-20240904': 1444,\n",
       "         'reka-flash-20240904': 1430,\n",
       "         'NousResearch/Hermes-3-Llama-3.1-8B': 1408,\n",
       "         'chatgpt-4o-latest-20240808': 1375,\n",
       "         'mpt-30b-chat': 1299,\n",
       "         'microsoft/Phi-3.5-mini-instruct': 1294,\n",
       "         'google/gemma-2-27b-it': 1230,\n",
       "         'gemini-1.5-flash-exp-0827': 1168,\n",
       "         'llama-3.1-nemotron-70b-instruct': 1141,\n",
       "         'wizardlm-70b': 1122,\n",
       "         'Qwen/QwQ-32B-Preview': 1117,\n",
       "         'mistral-7b-instruct': 1098,\n",
       "         'claude-3-5-sonnet-20241022': 1085,\n",
       "         'openchat-3.5': 1066,\n",
       "         'gemini-pro-dev-api': 1043,\n",
       "         'codellama-34b-instruct': 1027,\n",
       "         'pplx-70b-online': 1015,\n",
       "         'gemini-pro': 1008,\n",
       "         'gemini-1.5-pro-exp-0827': 1003,\n",
       "         'yi-34b-chat': 973,\n",
       "         'gpt-4-turbo-2024-04-09': 972,\n",
       "         'gpt-3.5-turbo-0314': 968,\n",
       "         'pplx-7b-online': 897,\n",
       "         'gemma-2-9b-it': 825,\n",
       "         'tulu-2-dpo-70b': 817,\n",
       "         'starling-lm-7b-alpha': 770,\n",
       "         'gemini-1.5-flash-001': 761,\n",
       "         'qwen-14b-chat': 709,\n",
       "         'chatglm3-6b': 695,\n",
       "         'solar-10.7b-instruct-v1.0': 614,\n",
       "         'gemini-1.5-pro-001': 611,\n",
       "         'openhermes-2.5-mistral-7b': 609,\n",
       "         'stripedhyena-nous-7b': 606,\n",
       "         'gpt-3.5-turbo-0125': 576,\n",
       "         'deepseek-llm-67b-chat': 519,\n",
       "         'llama2-70b-steerlm-chat': 458,\n",
       "         'llama-3.1-nemotron-51b-instruct': 456,\n",
       "         'c4ai-aya-expanse-32b': 449,\n",
       "         'gemma-2-9b-it-simpo': 439,\n",
       "         'jamba-1.5-large': 415,\n",
       "         'chatglm2-6b': 393,\n",
       "         'jamba-1.5-mini': 392,\n",
       "         'qwen1.5-72b-chat': 370,\n",
       "         'qwen2-72b-instruct': 364,\n",
       "         'athene-70b-0725': 338,\n",
       "         'zephyr-7b-alpha': 267,\n",
       "         'dolphin-2.2.1-mistral-7b': 240,\n",
       "         'nous-hermes-2-mixtral-8x7b-dpo': 235,\n",
       "         'deepseek-coder-v2-0724': 232,\n",
       "         'phi-3-medium-4k-instruct': 216,\n",
       "         'claude-2': 210,\n",
       "         'falcon-180b-chat': 203,\n",
       "         'reka-flash-20240722': 184,\n",
       "         'reka-core-20240722': 174,\n",
       "         'mixtral-8x22b-instruct-v0.1': 165,\n",
       "         'openchat-3.5-0106': 159,\n",
       "         'qwen1.5-7b-chat': 140,\n",
       "         'deepseek-v2-api-0628': 131,\n",
       "         'qwen1.5-4b-chat': 124,\n",
       "         'mistral-7b-instruct-v0.2': 72})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(final_df[\"model_a\"].tolist() + final_df[\"model_b\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "lmsys_125k_multilingual_gemma2_llama3_ensemble_stage1    125878\n",
       "current_comp                                              48439\n",
       "orpo_dpo_mix_40k                                          44245\n",
       "prev_comp                                                 39716\n",
       "lmsys_33k                                                 17909\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hard_labels\n",
       "1    139807\n",
       "0    136380\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"hard_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "English       126034\n",
       "Chinese        23801\n",
       "Russian        21585\n",
       "Portuguese     15402\n",
       "unknown        14029\n",
       "               ...  \n",
       "Telugu             1\n",
       "Maori              1\n",
       "Khmer              1\n",
       "Assamese           1\n",
       "Dzongkha           1\n",
       "Name: count, Length: 155, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    271348\n",
       "valid      4839\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_parquet(\"../data/train_orig_plus_pseudo_v1.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
