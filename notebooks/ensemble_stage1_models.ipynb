{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df[\"labels\"] = df[\"winner\"].map({\"model_a\": 0, \"model_b\": 1})\n",
    "    df = df[['id', 'logits', 'logits_tta', 'labels']].copy()\n",
    "    df = df.sort_values(by='id').reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_model_dataframes(dfs):\n",
    "    result = None\n",
    "    for model_name, df in dfs.items():\n",
    "        temp_df = df.copy()\n",
    "\n",
    "        new_columns = {\n",
    "            'logits': f'logits_{model_name}',\n",
    "            'logits_tta': f'logits_tta_{model_name}',\n",
    "            'labels': f'labels_{model_name}'  # Including labels if needed\n",
    "        }\n",
    "        \n",
    "        temp_df = temp_df.rename(columns=new_columns)\n",
    "        \n",
    "        if result is None:\n",
    "            result = temp_df\n",
    "        else:\n",
    "            # Merge on 'id' column\n",
    "            result = pd.merge(result, temp_df, on='id', how='outer')\n",
    "\n",
    "    # After all merges are done, keep only one labels column and rename it\n",
    "    labels_columns = [col for col in result.columns if col.startswith('labels_')]\n",
    "    if labels_columns:\n",
    "        # Keep the first labels column and rename it\n",
    "        result = result.rename(columns={labels_columns[0]: 'labels'})\n",
    "        # Drop all other labels columns\n",
    "        result = result.drop(columns=labels_columns[1:])    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> weight for logits and (1 - weight for logits_tta)\n",
    "\n",
    "# - (0.7179169249845009, 0.6891919818144244, 0.6931184128952262) -> 0.5\n",
    "# - (0.7154370737755734, 0.6898119446166563, 0.6949783013019218) -> 0.6\n",
    "# - (0.7164703451126265, 0.6896052903492457, 0.6978714610456705) -> 0.4\n",
    "# - (0.7141971481711097, 0.689398636081835, 0.7013845835916511) -> 0.3\n",
    "# - (0.712957222566646, 0.69105187022112, 0.6931184128952262) -> 0.7\n",
    "\n",
    "# (0.7057243232072742, 0.6881587104773713, 0.6846455879313907) -> without tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/pseudo_labeled_final_data/eval_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    'gemma9b': load_data(data_dir / \"eval_data_gemma2_9b_stage1_init_stage0_combined.parquet\"),\n",
    "    'llama': load_data(data_dir / \"eval_data_deepseek_llama3.18B_stage1_init_stage0_combined.parquet\"),\n",
    "    'qwen': load_data(data_dir / \"eval_data_qwen_2.5_7B_stage1_init_stage0_combined.parquet\"),\n",
    "    'gemma27b': load_data(data_dir / \"eval_data_gemma2_27B_stage1_lora_707_combined.parquet\"),\n",
    "    'phi4': load_data(data_dir / \"eval_data_phi4_stage1_lora_700_combined.parquet\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma9b 0.7179169249845009\n",
      "llama 0.6891919818144244\n",
      "qwen 0.6933250671626369\n",
      "gemma27b 0.7131638768340566\n",
      "phi4 0.703657780533168\n"
     ]
    }
   ],
   "source": [
    "for model_name, d in dfs.items():\n",
    "    logits = 0.5 * np.array(d[\"logits\"].tolist()) + 0.5 * np.array(d[\"logits_tta\"].tolist())\n",
    "    print(model_name, accuracy_score(d[\"labels\"], np.argmax(logits, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>logits_gemma9b</th>\n",
       "      <th>logits_tta_gemma9b</th>\n",
       "      <th>labels</th>\n",
       "      <th>logits_llama</th>\n",
       "      <th>logits_tta_llama</th>\n",
       "      <th>logits_qwen</th>\n",
       "      <th>logits_tta_qwen</th>\n",
       "      <th>logits_gemma27b</th>\n",
       "      <th>logits_tta_gemma27b</th>\n",
       "      <th>logits_phi4</th>\n",
       "      <th>logits_tta_phi4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n",
       "      <td>[1.390625, -0.46875]</td>\n",
       "      <td>[0.68359375, -0.1435546875]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0078125, -0.453125]</td>\n",
       "      <td>[0.39453125, -0.024658203125]</td>\n",
       "      <td>[0.84765625, -1.5390625]</td>\n",
       "      <td>[0.380859375, -0.7109375]</td>\n",
       "      <td>[-0.08837890625, -2.640625]</td>\n",
       "      <td>[-0.98828125, -1.515625]</td>\n",
       "      <td>[1.265625, -0.55859375]</td>\n",
       "      <td>[0.76171875, -0.50390625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00172aab8af10cc0648041c94a41eeab7d9caaea7717a3...</td>\n",
       "      <td>[0.625, 0.1416015625]</td>\n",
       "      <td>[0.419921875, 0.228515625]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3515625, -0.055908203125]</td>\n",
       "      <td>[0.4296875, -0.1298828125]</td>\n",
       "      <td>[-0.134765625, -0.333984375]</td>\n",
       "      <td>[-0.58984375, 0.040771484375]</td>\n",
       "      <td>[-0.9140625, -1.515625]</td>\n",
       "      <td>[-1.5859375, -0.91796875]</td>\n",
       "      <td>[0.142578125, 0.1728515625]</td>\n",
       "      <td>[-0.1865234375, 0.58984375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00314ee979ffc9e4e4dd3716d02c401ba117d00640a3e1...</td>\n",
       "      <td>[1.2265625, -0.5]</td>\n",
       "      <td>[1.5859375, -1.078125]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.234375, -0.72265625]</td>\n",
       "      <td>[1.328125, -0.98046875]</td>\n",
       "      <td>[0.609375, -1.25]</td>\n",
       "      <td>[0.7734375, -1.0234375]</td>\n",
       "      <td>[0.023681640625, -2.28125]</td>\n",
       "      <td>[-0.181640625, -1.8125]</td>\n",
       "      <td>[1.2265625, -0.494140625]</td>\n",
       "      <td>[1.109375, -1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003aa0a76eb58c06adce6e9db59ad1da73929a431f3f23...</td>\n",
       "      <td>[0.484375, 0.1904296875]</td>\n",
       "      <td>[0.32421875, 0.34375]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.26171875, 0.046630859375]</td>\n",
       "      <td>[0.076171875, 0.298828125]</td>\n",
       "      <td>[-0.1240234375, -0.345703125]</td>\n",
       "      <td>[-0.515625, -0.003753662109375]</td>\n",
       "      <td>[-0.90234375, -1.546875]</td>\n",
       "      <td>[-1.6171875, -0.91796875]</td>\n",
       "      <td>[0.24609375, 0.1337890625]</td>\n",
       "      <td>[0.060791015625, 0.345703125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00448e4160ceb9578584293b6aee5d680c8e6dbbcd1d13...</td>\n",
       "      <td>[0.75390625, -0.0167236328125]</td>\n",
       "      <td>[0.5859375, 0.09228515625]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.15625, 0.12451171875]</td>\n",
       "      <td>[0.291015625, 0.06005859375]</td>\n",
       "      <td>[0.061279296875, -0.5703125]</td>\n",
       "      <td>[-0.06201171875, -0.37890625]</td>\n",
       "      <td>[-0.6015625, -2.078125]</td>\n",
       "      <td>[-1.34375, -1.2109375]</td>\n",
       "      <td>[0.66015625, -0.2421875]</td>\n",
       "      <td>[0.546875, -0.185546875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>ffc2a1a209a1053658645fc60dd29249392c7e0040ae5d...</td>\n",
       "      <td>[-1.7890625, 2.3125]</td>\n",
       "      <td>[-1.34375, 2.0625]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.859375, 2.109375]</td>\n",
       "      <td>[-1.125, 1.8359375]</td>\n",
       "      <td>[-1.4921875, 1.4296875]</td>\n",
       "      <td>[-2.140625, 1.3828125]</td>\n",
       "      <td>[-2.796875, 0.396484375]</td>\n",
       "      <td>[-3.109375, 0.337890625]</td>\n",
       "      <td>[-1.7890625, 1.875]</td>\n",
       "      <td>[-1.109375, 1.6953125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>ffd929efef61e5b353180a6e790d35896363ecf02973ee...</td>\n",
       "      <td>[0.921875, -0.2080078125]</td>\n",
       "      <td>[0.5625, -0.00811767578125]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.87109375, -0.443359375]</td>\n",
       "      <td>[0.68359375, -0.365234375]</td>\n",
       "      <td>[0.28125, -0.8671875]</td>\n",
       "      <td>[-0.076171875, -0.361328125]</td>\n",
       "      <td>[-0.78125, -1.703125]</td>\n",
       "      <td>[-1.34375, -0.9921875]</td>\n",
       "      <td>[0.0927734375, 0.30078125]</td>\n",
       "      <td>[0.796875, -0.482421875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>ffe2645c0cdb2cbbb755ad0766cfc14663726619968c4e...</td>\n",
       "      <td>[0.00250244140625, 0.490234375]</td>\n",
       "      <td>[-0.06787109375, 0.859375]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0042724609375, 0.375]</td>\n",
       "      <td>[0.05322265625, 0.271484375]</td>\n",
       "      <td>[-0.359375, -0.09716796875]</td>\n",
       "      <td>[-0.7734375, 0.212890625]</td>\n",
       "      <td>[-1.2421875, -1.265625]</td>\n",
       "      <td>[-1.71875, -0.86328125]</td>\n",
       "      <td>[-0.369140625, 0.68359375]</td>\n",
       "      <td>[0.197265625, 0.10400390625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>ffe2a8b3cf149dc4ffd040623f4c8e4e9e87b98bd41b14...</td>\n",
       "      <td>[0.0025177001953125, 0.60546875]</td>\n",
       "      <td>[-0.039306640625, 0.75]</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.31640625, 0.60546875]</td>\n",
       "      <td>[-0.09765625, 0.486328125]</td>\n",
       "      <td>[-0.546875, 0.171875]</td>\n",
       "      <td>[-0.984375, 0.39453125]</td>\n",
       "      <td>[-1.2578125, -1.0625]</td>\n",
       "      <td>[-1.9609375, -0.6875]</td>\n",
       "      <td>[-0.072265625, 0.4140625]</td>\n",
       "      <td>[-0.103515625, 0.56640625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>fffd2ffdaa03e9e0a0cd1e8f2ee80f530bb19b08fa4312...</td>\n",
       "      <td>[0.26171875, 0.388671875]</td>\n",
       "      <td>[0.69140625, -0.11572265625]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.48828125, -0.13671875]</td>\n",
       "      <td>[0.63671875, -0.291015625]</td>\n",
       "      <td>[0.2373046875, -0.79296875]</td>\n",
       "      <td>[0.072265625, -0.47265625]</td>\n",
       "      <td>[-0.625, -2.015625]</td>\n",
       "      <td>[-0.8359375, -1.453125]</td>\n",
       "      <td>[0.60546875, -0.15234375]</td>\n",
       "      <td>[0.7421875, -0.478515625]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4839 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n",
       "1     00172aab8af10cc0648041c94a41eeab7d9caaea7717a3...   \n",
       "2     00314ee979ffc9e4e4dd3716d02c401ba117d00640a3e1...   \n",
       "3     003aa0a76eb58c06adce6e9db59ad1da73929a431f3f23...   \n",
       "4     00448e4160ceb9578584293b6aee5d680c8e6dbbcd1d13...   \n",
       "...                                                 ...   \n",
       "4834  ffc2a1a209a1053658645fc60dd29249392c7e0040ae5d...   \n",
       "4835  ffd929efef61e5b353180a6e790d35896363ecf02973ee...   \n",
       "4836  ffe2645c0cdb2cbbb755ad0766cfc14663726619968c4e...   \n",
       "4837  ffe2a8b3cf149dc4ffd040623f4c8e4e9e87b98bd41b14...   \n",
       "4838  fffd2ffdaa03e9e0a0cd1e8f2ee80f530bb19b08fa4312...   \n",
       "\n",
       "                        logits_gemma9b            logits_tta_gemma9b  labels  \\\n",
       "0                 [1.390625, -0.46875]   [0.68359375, -0.1435546875]       0   \n",
       "1                [0.625, 0.1416015625]    [0.419921875, 0.228515625]       1   \n",
       "2                    [1.2265625, -0.5]        [1.5859375, -1.078125]       0   \n",
       "3             [0.484375, 0.1904296875]         [0.32421875, 0.34375]       0   \n",
       "4       [0.75390625, -0.0167236328125]    [0.5859375, 0.09228515625]       0   \n",
       "...                                ...                           ...     ...   \n",
       "4834              [-1.7890625, 2.3125]            [-1.34375, 2.0625]       1   \n",
       "4835         [0.921875, -0.2080078125]   [0.5625, -0.00811767578125]       0   \n",
       "4836   [0.00250244140625, 0.490234375]    [-0.06787109375, 0.859375]       1   \n",
       "4837  [0.0025177001953125, 0.60546875]       [-0.039306640625, 0.75]       0   \n",
       "4838         [0.26171875, 0.388671875]  [0.69140625, -0.11572265625]       0   \n",
       "\n",
       "                      logits_llama               logits_tta_llama  \\\n",
       "0           [1.0078125, -0.453125]  [0.39453125, -0.024658203125]   \n",
       "1     [0.3515625, -0.055908203125]     [0.4296875, -0.1298828125]   \n",
       "2          [1.234375, -0.72265625]        [1.328125, -0.98046875]   \n",
       "3     [0.26171875, 0.046630859375]     [0.076171875, 0.298828125]   \n",
       "4         [0.15625, 0.12451171875]   [0.291015625, 0.06005859375]   \n",
       "...                            ...                            ...   \n",
       "4834         [-1.859375, 2.109375]            [-1.125, 1.8359375]   \n",
       "4835    [0.87109375, -0.443359375]     [0.68359375, -0.365234375]   \n",
       "4836     [-0.0042724609375, 0.375]   [0.05322265625, 0.271484375]   \n",
       "4837     [-0.31640625, 0.60546875]     [-0.09765625, 0.486328125]   \n",
       "4838     [0.48828125, -0.13671875]     [0.63671875, -0.291015625]   \n",
       "\n",
       "                        logits_qwen                  logits_tta_qwen  \\\n",
       "0          [0.84765625, -1.5390625]        [0.380859375, -0.7109375]   \n",
       "1      [-0.134765625, -0.333984375]    [-0.58984375, 0.040771484375]   \n",
       "2                 [0.609375, -1.25]          [0.7734375, -1.0234375]   \n",
       "3     [-0.1240234375, -0.345703125]  [-0.515625, -0.003753662109375]   \n",
       "4      [0.061279296875, -0.5703125]    [-0.06201171875, -0.37890625]   \n",
       "...                             ...                              ...   \n",
       "4834        [-1.4921875, 1.4296875]           [-2.140625, 1.3828125]   \n",
       "4835          [0.28125, -0.8671875]     [-0.076171875, -0.361328125]   \n",
       "4836    [-0.359375, -0.09716796875]        [-0.7734375, 0.212890625]   \n",
       "4837          [-0.546875, 0.171875]          [-0.984375, 0.39453125]   \n",
       "4838    [0.2373046875, -0.79296875]       [0.072265625, -0.47265625]   \n",
       "\n",
       "                  logits_gemma27b        logits_tta_gemma27b  \\\n",
       "0     [-0.08837890625, -2.640625]   [-0.98828125, -1.515625]   \n",
       "1         [-0.9140625, -1.515625]  [-1.5859375, -0.91796875]   \n",
       "2      [0.023681640625, -2.28125]    [-0.181640625, -1.8125]   \n",
       "3        [-0.90234375, -1.546875]  [-1.6171875, -0.91796875]   \n",
       "4         [-0.6015625, -2.078125]     [-1.34375, -1.2109375]   \n",
       "...                           ...                        ...   \n",
       "4834     [-2.796875, 0.396484375]   [-3.109375, 0.337890625]   \n",
       "4835        [-0.78125, -1.703125]     [-1.34375, -0.9921875]   \n",
       "4836      [-1.2421875, -1.265625]    [-1.71875, -0.86328125]   \n",
       "4837        [-1.2578125, -1.0625]      [-1.9609375, -0.6875]   \n",
       "4838          [-0.625, -2.015625]    [-0.8359375, -1.453125]   \n",
       "\n",
       "                      logits_phi4                logits_tta_phi4  \n",
       "0         [1.265625, -0.55859375]      [0.76171875, -0.50390625]  \n",
       "1     [0.142578125, 0.1728515625]    [-0.1865234375, 0.58984375]  \n",
       "2       [1.2265625, -0.494140625]               [1.109375, -1.0]  \n",
       "3      [0.24609375, 0.1337890625]  [0.060791015625, 0.345703125]  \n",
       "4        [0.66015625, -0.2421875]       [0.546875, -0.185546875]  \n",
       "...                           ...                            ...  \n",
       "4834          [-1.7890625, 1.875]         [-1.109375, 1.6953125]  \n",
       "4835   [0.0927734375, 0.30078125]       [0.796875, -0.482421875]  \n",
       "4836   [-0.369140625, 0.68359375]   [0.197265625, 0.10400390625]  \n",
       "4837    [-0.072265625, 0.4140625]     [-0.103515625, 0.56640625]  \n",
       "4838    [0.60546875, -0.15234375]      [0.7421875, -0.478515625]  \n",
       "\n",
       "[4839 rows x 12 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renamed_dfs = {}\n",
    "for model_name, df in dfs.items():\n",
    "    # Create a copy and rename all columns except the ID column (assuming there's an ID column)\n",
    "    temp_df = df.copy()\n",
    "    # Get columns that need to be renamed (exclude 'id' if it exists)\n",
    "    cols_to_rename = [col for col in temp_df.columns if col != 'id']\n",
    "    # Create rename mapping\n",
    "    rename_dict = {col: f\"{col}_{model_name}\" for col in cols_to_rename}\n",
    "    temp_df = temp_df.rename(columns=rename_dict)\n",
    "    renamed_dfs[model_name] = temp_df\n",
    "\n",
    "\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), \n",
    "                  renamed_dfs.values())\n",
    "\n",
    "columns_to_drop = [\n",
    "    'labels_llama',\n",
    "    'labels_qwen',\n",
    "    'labels_gemma27b',\n",
    "    'labels_phi4'\n",
    "]\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)\n",
    "merged_df = merged_df.rename(columns={'labels_gemma9b': 'labels'})\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logits = {\n",
    "    'gemma9b': 0.5 * np.array(merged_df[\"logits_gemma9b\"].tolist()) + 0.5 * np.array(merged_df[\"logits_tta_gemma9b\"].tolist()),\n",
    "    'llama': 0.5 * np.array(merged_df[\"logits_llama\"].tolist()) + 0.5 * np.array(merged_df[\"logits_tta_llama\"].tolist()),\n",
    "    'qwen': 0.5 * np.array(merged_df[\"logits_qwen\"].tolist()) + 0.5 * np.array(merged_df[\"logits_tta_qwen\"].tolist()),\n",
    "    'gemma27b': 0.5 * np.array(merged_df[\"logits_gemma27b\"].tolist()) + 0.5 * np.array(merged_df[\"logits_tta_gemma27b\"].tolist()),\n",
    "    'phi4': 0.5 * np.array(merged_df[\"logits_phi4\"].tolist()) + 0.5 * np.array(merged_df[\"logits_tta_phi4\"].tolist())\n",
    "}\n",
    "true_labels = np.array(merged_df[\"labels\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma9b: 0.7179169249845009\n",
      "llama: 0.6891919818144244\n",
      "qwen: 0.6933250671626369\n",
      "gemma27b: 0.7131638768340566\n",
      "phi4: 0.703657780533168\n"
     ]
    }
   ],
   "source": [
    "for m, l in model_logits.items():\n",
    "    acc = accuracy_score(true_labels, l.argmax(-1))\n",
    "    print(f\"{m}: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "class EnsembleOptimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_logits: Dict[str, np.ndarray],\n",
    "        true_labels: np.ndarray,\n",
    "        max_models: int = 6,\n",
    "        weight_range: Tuple[float, float] = (0.0, 1.0),\n",
    "        weight_steps: int = 10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the ensemble optimizer.\n",
    "        \n",
    "        Args:\n",
    "            model_logits: Dictionary of model names to logits arrays\n",
    "            true_labels: Ground truth labels\n",
    "            max_models: Maximum number of models to include in ensemble\n",
    "            weight_range: Range of weights to try\n",
    "            weight_steps: Number of weight values to try in the range\n",
    "        \"\"\"\n",
    "        self.model_logits = model_logits\n",
    "        self.true_labels = true_labels\n",
    "        self.max_models = max_models\n",
    "        self.weight_range = weight_range\n",
    "        self.weight_steps = weight_steps\n",
    "        \n",
    "    def compute_accuracy(self, combined_logits: np.ndarray) -> float:\n",
    "        \"\"\"Compute accuracy from combined logits\"\"\"\n",
    "        predictions = (combined_logits[:, 1] > combined_logits[:, 0]).astype(int)\n",
    "        return np.mean(predictions == self.true_labels)\n",
    "    \n",
    "    def combine_logits(self, models: List[str], weights: List[float]) -> np.ndarray:\n",
    "        \"\"\"Combine logits from multiple models using given weights\"\"\"\n",
    "        combined = np.zeros_like(self.model_logits[models[0]])\n",
    "        for model, weight in zip(models, weights):\n",
    "            combined += weight * self.model_logits[model]\n",
    "        return combined\n",
    "    \n",
    "    def optimize_weights(self, current_models: List[str], new_model: str) -> Tuple[List[float], float]:\n",
    "        \"\"\"Find optimal weights for combining current models with a new model\"\"\"\n",
    "        n_models = len(current_models) + 1\n",
    "        best_accuracy = 0\n",
    "        best_weights = None\n",
    "        \n",
    "        # Generate weight combinations\n",
    "        weight_values = np.linspace(self.weight_range[0], self.weight_range[1], self.weight_steps)\n",
    "        \n",
    "        for weights in combinations(weight_values, n_models):\n",
    "            # Normalize weights to sum to 1\n",
    "            weights = np.array(weights) / sum(weights)\n",
    "            \n",
    "            # Combine logits\n",
    "            combined = self.combine_logits(current_models + [new_model], weights)\n",
    "            accuracy = self.compute_accuracy(combined)\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_weights = weights\n",
    "                \n",
    "        return best_weights, best_accuracy\n",
    "    \n",
    "    def hill_climb(self) -> Tuple[List[str], List[float], float]:\n",
    "        \"\"\"\n",
    "        Perform hill climbing to find optimal model combination.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (best models, best weights, best accuracy)\n",
    "        \"\"\"\n",
    "        # Start with best single model\n",
    "        best_models = []\n",
    "        best_weights = []\n",
    "        best_accuracy = 0\n",
    "        \n",
    "        for model in self.model_logits.keys():\n",
    "            accuracy = self.compute_accuracy(self.model_logits[model])\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_models = [model]\n",
    "                best_weights = [1.0]\n",
    "        \n",
    "        # Iteratively add models\n",
    "        available_models = set(self.model_logits.keys()) - set(best_models)\n",
    "        \n",
    "        while len(best_models) < self.max_models and available_models:\n",
    "            improved = False\n",
    "            best_new_accuracy = best_accuracy\n",
    "            best_new_model = None\n",
    "            best_new_weights = None\n",
    "            \n",
    "            # Try adding each available model\n",
    "            for model in available_models:\n",
    "                weights, accuracy = self.optimize_weights(best_models, model)\n",
    "                \n",
    "                if accuracy > best_new_accuracy:\n",
    "                    improved = True\n",
    "                    best_new_accuracy = accuracy\n",
    "                    best_new_model = model\n",
    "                    best_new_weights = weights\n",
    "            \n",
    "            if not improved:\n",
    "                break\n",
    "                \n",
    "            # Update best ensemble\n",
    "            best_accuracy = best_new_accuracy\n",
    "            best_models.append(best_new_model)\n",
    "            best_weights = best_new_weights\n",
    "            available_models.remove(best_new_model)\n",
    "            \n",
    "        return best_models, best_weights, best_accuracy\n",
    "\n",
    "# Example usage:\n",
    "def optimize_ensemble(all_logits: Dict[str, np.ndarray], true_labels: np.ndarray) -> Tuple[List[str], List[float], float]:\n",
    "    \"\"\"\n",
    "    Optimize ensemble weights using hill climbing.\n",
    "    \n",
    "    Args:\n",
    "        all_logits: Dictionary mapping model names to their logit outputs\n",
    "        true_labels: Ground truth labels\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best model names, best weights, best accuracy)\n",
    "    \"\"\"\n",
    "    optimizer = EnsembleOptimizer(\n",
    "        model_logits=all_logits,\n",
    "        true_labels=true_labels,\n",
    "        max_models=10,  # Maximum models to include\n",
    "        weight_range=(0.0, 1.0),  # Range of weights to try\n",
    "        weight_steps=10  # Number of weight values to try\n",
    "    )\n",
    "    \n",
    "    return optimizer.hill_climb()\n",
    "\n",
    "\n",
    "\n",
    "def brute_force_weights(model_logits, true_labels, step_size=0.1):\n",
    "    \"\"\"\n",
    "    Find optimal weights for ensemble models using grid search.\n",
    "    \"\"\"\n",
    "    # Get model names\n",
    "    models = list(model_logits.keys())\n",
    "    \n",
    "    # Generate weight combinations that sum to 1\n",
    "    weights = np.arange(0, 1 + step_size, step_size)\n",
    "    combinations = []\n",
    "    \n",
    "    # Generate all possible weight combinations\n",
    "    for w in product(weights, repeat=len(models)):\n",
    "        if abs(sum(w) - 1.0) < 1e-10:  # Check if weights sum to 1\n",
    "            combinations.append(w)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_weights = None\n",
    "    \n",
    "    # Try each weight combination\n",
    "    for weights in combinations:\n",
    "        # Compute weighted ensemble logits\n",
    "        ensemble_logits = sum(w * model_logits[m] for w, m in zip(weights, models))\n",
    "        \n",
    "        # Get predictions and compute accuracy\n",
    "        predictions = np.argmax(ensemble_logits, axis=-1)\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        \n",
    "        # Update best weights if accuracy improves\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_weights = dict(zip(models, weights))\n",
    "            \n",
    "    return best_weights, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logits = {\n",
    "    'gemma9b': (np.array(merged_df[\"logits_gemma9b\"].to_list()) + np.array(merged_df[\"logits_tta_gemma9b\"].to_list())) / 2,\n",
    "    'llama': (np.array(merged_df[\"logits_llama\"].to_list()) + np.array(merged_df[\"logits_tta_llama\"].to_list())) / 2,\n",
    "    'qwen': (np.array(merged_df[\"logits_qwen\"].to_list()) + np.array(merged_df[\"logits_tta_qwen\"].to_list())) / 2,\n",
    "    'gemma27b': (np.array(merged_df[\"logits_gemma27b\"].to_list()) + np.array(merged_df[\"logits_tta_gemma27b\"].to_list())) / 2,\n",
    "    'phi4': (np.array(merged_df[\"logits_phi4\"].to_list()) + np.array(merged_df[\"logits_tta_phi4\"].to_list())) / 2,\n",
    "}\n",
    "true_labels = np.array(merged_df[\"labels\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gemma9b accuracy: 0.7179169249845009\n",
      "Model llama accuracy: 0.6891919818144244\n",
      "Model qwen accuracy: 0.6933250671626369\n",
      "Model gemma27b accuracy: 0.7131638768340566\n",
      "Model phi4 accuracy: 0.703657780533168\n"
     ]
    }
   ],
   "source": [
    "for model, logits in model_logits.items():\n",
    "    acc = accuracy_score(true_labels, np.argmax(logits, axis=-1))\n",
    "    print(f\"Model {model} accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['gemma9b', 'gemma27b'], array([0.45454545, 0.54545455]), 0.7201901219260177)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_ensemble(model_logits, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'gemma9b': 0.55, 'llama': 0.0, 'qwen': 0.0, 'gemma27b': 0.2, 'phi4': 0.25},\n",
       " 0.7237)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights, best_accuracy = brute_force_weights(model_logits, true_labels, step_size=0.05)\n",
    "best_weights, round(best_accuracy, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ({'gemma9b': 0.4, 'llama': 0.0, 'qwen': 0.2, 'gemma27b': 0.4, 'phi4': 0.0} -> step_size = 0.1\n",
    "# ({'gemma9b': 0.55, 'llama': 0.0, 'qwen': 0.0, 'gemma27b': 0.2, 'phi4': 0.25} -> step_size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = {'gemma9b': 0.55, 'gemma27b': 0.2, 'phi4': 0.25} # score: 0.7237\n",
    "# best_weights = {'gemma9b': 0.333, 'gemma27b': 0.33333, 'phi4': 0.33333} # average: 0.7179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7237"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_logits = 0\n",
    "for model, weight in best_weights.items():\n",
    "    if weight > 0:\n",
    "        ensemble_logits += model_logits[model] * weight\n",
    "acc = round(accuracy_score(true_labels, np.argmax(ensemble_logits, axis=-1)), 4)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>logits</th>\n",
       "      <th>logits_tta</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41b149ae0c7e8c40d72b26312d4e40a32b903d83e5432c...</td>\n",
       "      <td>شوند. سناریوی زیر را در نظر 􀍬 پردازنده اجرا م ...</td>\n",
       "      <td>بیایید سناریوی مطرح شده را به تفصیل تحلیل کنیم...</td>\n",
       "      <td>برای تحلیل سناریوی ارائه شده در مورد رویدادهای...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>Persian</td>\n",
       "      <td>train</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.55859375, -0.1015625]</td>\n",
       "      <td>[0.67578125, -0.345703125]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72551638</td>\n",
       "      <td>using UnityEngine;\\nusing System.Text;\\n\\npubl...</td>\n",
       "      <td>Here are a few ways to improve the console com...</td>\n",
       "      <td>This script appears to be a simple in-game con...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>prev_comp</td>\n",
       "      <td>[0.03662109375, 0.392578125]</td>\n",
       "      <td>[-0.125, 0.640625]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24d45b90e7dd908f35f9af57a264aee2e9982d14960104...</td>\n",
       "      <td>A point mass P, mass = 6 * 10^24kg, is fixed a...</td>\n",
       "      <td>To solve the problem, we'll analyze the motion...</td>\n",
       "      <td>To solve this problem, we need to calculate th...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.54296875, -0.051025390625]</td>\n",
       "      <td>[0.4609375, -0.08984375]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>097c490a923a5987947089da7f4ae79ceaedc598d14941...</td>\n",
       "      <td>Упрости текст для легкого запоминания : Античн...</td>\n",
       "      <td>### Античная философия и медицина\\n\\nНатурфило...</td>\n",
       "      <td>Antičная философия и медицина - это две민Startu...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>mistral-large-2407</td>\n",
       "      <td>llama-3.2-1b-instruct</td>\n",
       "      <td>Russian</td>\n",
       "      <td>train</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[2.125, -1.4296875]</td>\n",
       "      <td>[1.765625, -1.75]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5184bb73881a2fc67211b6090dc50b99a9dfa2e9782bdc...</td>\n",
       "      <td>Подготовить программу наставничества . 1. Инди...</td>\n",
       "      <td>**Программа Наставничества**\\n\\n**Цель:** Сокр...</td>\n",
       "      <td>### Программа наставничества\\n\\n#### Цель прог...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>yi-lightning</td>\n",
       "      <td>Russian</td>\n",
       "      <td>train</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[-0.447265625, 0.75]</td>\n",
       "      <td>[-0.2177734375, 0.73828125]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>3274457708</td>\n",
       "      <td>dog -&gt; puppy, animal, canine\\nocean -&gt;</td>\n",
       "      <td>marine, aquatic, sea, sea creature</td>\n",
       "      <td>dog -&gt; puppy, animal, canine\\nocean -&gt; ocean a...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>prev_comp</td>\n",
       "      <td>[2.296875, -1.671875]</td>\n",
       "      <td>[2.28125, -2.359375]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>b9b6c538eb1f4357a81049ac22c5e3ad</td>\n",
       "      <td>what's 3 times 20100?</td>\n",
       "      <td>3 times 20100 is 60,300.</td>\n",
       "      <td>3 times 20100 is equal to 60200.</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>lmsys_33k</td>\n",
       "      <td>[1.7578125, -1.0703125]</td>\n",
       "      <td>[1.0703125, -0.98828125]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>27c0475986a9af98659979ef6be5c1b2980aba11c37565...</td>\n",
       "      <td>Who you one short sentence</td>\n",
       "      <td>I am an AI assistant.</td>\n",
       "      <td>I am an AI assistant here to help you.</td>\n",
       "      <td>model_b</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>qwen-plus-0828</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[-0.1787109375, 0.41796875]</td>\n",
       "      <td>[0.07080078125, 0.318359375]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3765590473</td>\n",
       "      <td>hey!</td>\n",
       "      <td>Hey there! How's it going?</td>\n",
       "      <td>Hey there! How's it going?</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>prev_comp</td>\n",
       "      <td>[0.26171875, 0.103515625]</td>\n",
       "      <td>[0.10009765625, 0.26171875]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>22f7a0b8ed73c2fba744899316080c617ded3161900295...</td>\n",
       "      <td>write your exact model name in two words</td>\n",
       "      <td>Large Language Model</td>\n",
       "      <td>BLOOM.</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemini-1.5-flash-8b-exp-0827</td>\n",
       "      <td>jamba-1.5-mini</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.54296875, -0.0277099609375]</td>\n",
       "      <td>[-0.146484375, 0.4609375]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id  \\\n",
       "0    41b149ae0c7e8c40d72b26312d4e40a32b903d83e5432c...   \n",
       "1                                             72551638   \n",
       "2    24d45b90e7dd908f35f9af57a264aee2e9982d14960104...   \n",
       "3    097c490a923a5987947089da7f4ae79ceaedc598d14941...   \n",
       "4    5184bb73881a2fc67211b6090dc50b99a9dfa2e9782bdc...   \n",
       "..                                                 ...   \n",
       "990                                         3274457708   \n",
       "991                   b9b6c538eb1f4357a81049ac22c5e3ad   \n",
       "997  27c0475986a9af98659979ef6be5c1b2980aba11c37565...   \n",
       "998                                         3765590473   \n",
       "999  22f7a0b8ed73c2fba744899316080c617ded3161900295...   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    شوند. سناریوی زیر را در نظر 􀍬 پردازنده اجرا م ...   \n",
       "1    using UnityEngine;\\nusing System.Text;\\n\\npubl...   \n",
       "2    A point mass P, mass = 6 * 10^24kg, is fixed a...   \n",
       "3    Упрости текст для легкого запоминания : Античн...   \n",
       "4    Подготовить программу наставничества . 1. Инди...   \n",
       "..                                                 ...   \n",
       "990             dog -> puppy, animal, canine\\nocean ->   \n",
       "991                              what's 3 times 20100?   \n",
       "997                         Who you one short sentence   \n",
       "998                                               hey!   \n",
       "999          write your exact model name in two words    \n",
       "\n",
       "                                            response_a  \\\n",
       "0    بیایید سناریوی مطرح شده را به تفصیل تحلیل کنیم...   \n",
       "1    Here are a few ways to improve the console com...   \n",
       "2    To solve the problem, we'll analyze the motion...   \n",
       "3    ### Античная философия и медицина\\n\\nНатурфило...   \n",
       "4    **Программа Наставничества**\\n\\n**Цель:** Сокр...   \n",
       "..                                                 ...   \n",
       "990                 marine, aquatic, sea, sea creature   \n",
       "991                           3 times 20100 is 60,300.   \n",
       "997                              I am an AI assistant.   \n",
       "998                         Hey there! How's it going?   \n",
       "999                               Large Language Model   \n",
       "\n",
       "                                            response_b   winner  \\\n",
       "0    برای تحلیل سناریوی ارائه شده در مورد رویدادهای...  model_a   \n",
       "1    This script appears to be a simple in-game con...  model_b   \n",
       "2    To solve this problem, we need to calculate th...  model_a   \n",
       "3    Antičная философия и медицина - это две민Startu...  model_b   \n",
       "4    ### Программа наставничества\\n\\n#### Цель прог...  model_b   \n",
       "..                                                 ...      ...   \n",
       "990  dog -> puppy, animal, canine\\nocean -> ocean a...  model_a   \n",
       "991                   3 times 20100 is equal to 60200.  model_a   \n",
       "997             I am an AI assistant here to help you.  model_b   \n",
       "998                         Hey there! How's it going?  model_a   \n",
       "999                                             BLOOM.  model_b   \n",
       "\n",
       "                          model_a                 model_b language  split  \\\n",
       "0            gemini-1.5-flash-002  gpt-4o-mini-2024-07-18  Persian  train   \n",
       "1                      claude-2.1      gpt-4-1106-preview  English  train   \n",
       "2                         o1-mini              o1-preview  English  train   \n",
       "3              mistral-large-2407   llama-3.2-1b-instruct  Russian  train   \n",
       "4           llama-3.1-8b-instruct            yi-lightning  Russian  train   \n",
       "..                            ...                     ...      ...    ...   \n",
       "990                   mpt-7b-chat            dolly-v2-12b  English  train   \n",
       "991                 gpt-3.5-turbo              chatglm-6b  English  train   \n",
       "997       claude-3-haiku-20240307          qwen-plus-0828  English  train   \n",
       "998              llama-2-13b-chat  codellama-34b-instruct  English  train   \n",
       "999  gemini-1.5-flash-8b-exp-0827          jamba-1.5-mini  English  train   \n",
       "\n",
       "           source                          logits  \\\n",
       "0    current_comp        [0.55859375, -0.1015625]   \n",
       "1       prev_comp    [0.03662109375, 0.392578125]   \n",
       "2    current_comp   [0.54296875, -0.051025390625]   \n",
       "3    current_comp             [2.125, -1.4296875]   \n",
       "4    current_comp            [-0.447265625, 0.75]   \n",
       "..            ...                             ...   \n",
       "990     prev_comp           [2.296875, -1.671875]   \n",
       "991     lmsys_33k         [1.7578125, -1.0703125]   \n",
       "997  current_comp     [-0.1787109375, 0.41796875]   \n",
       "998     prev_comp       [0.26171875, 0.103515625]   \n",
       "999  current_comp  [0.54296875, -0.0277099609375]   \n",
       "\n",
       "                       logits_tta  labels  \n",
       "0      [0.67578125, -0.345703125]       0  \n",
       "1              [-0.125, 0.640625]       1  \n",
       "2        [0.4609375, -0.08984375]       0  \n",
       "3               [1.765625, -1.75]       1  \n",
       "4     [-0.2177734375, 0.73828125]       1  \n",
       "..                            ...     ...  \n",
       "990          [2.28125, -2.359375]       0  \n",
       "991      [1.0703125, -0.98828125]       0  \n",
       "997  [0.07080078125, 0.318359375]       1  \n",
       "998   [0.10009765625, 0.26171875]       0  \n",
       "999     [-0.146484375, 0.4609375]       1  \n",
       "\n",
       "[533 rows x 13 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ddd = pd.read_parquet(\"../data/pseudo_labeled_final_data/pl_gemma2_27B_stage1_lora_707_merged_combined.parquet\")\n",
    "ddd = pd.read_parquet(\"../data/pseudo_labeled_final_data/pl_phi4_stage1_lora_700_merged.parquet\")\n",
    "ddd = ddd[ddd['split'] == 'train']\n",
    "ddd = ddd.dropna(subset=['winner'])\n",
    "ddd['labels'] = ddd['winner'].map({'model_a': 0, 'model_b': 1})\n",
    "ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954971857410882"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = np.array(ddd['logits'].to_list())\n",
    "logits_tta  = np.array(ddd['logits_tta'].to_list())\n",
    "l = (logits + logits_tta) / 2\n",
    "acc = accuracy_score(ddd['labels'], l.argmax(-1))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>labels</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n",
       "      <td>You will be given a piece of news. Analyze it ...</td>\n",
       "      <td>Let's break down the news and analyze it accor...</td>\n",
       "      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>Russian</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.865793</td>\n",
       "      <td>0.134208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00172aab8af10cc0648041c94a41eeab7d9caaea7717a3...</td>\n",
       "      <td>kısaca dopamin detoksu</td>\n",
       "      <td>Dopamin detoksu, beyninizin dopamin seviyeleri...</td>\n",
       "      <td>Dopamin detoksunun amacı, aşırı uyarılmaya ned...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>grok-2-2024-08-13</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679179</td>\n",
       "      <td>0.320821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00314ee979ffc9e4e4dd3716d02c401ba117d00640a3e1...</td>\n",
       "      <td>In Webgpu/WGSL, what are override variables?</td>\n",
       "      <td>In **WebGPU** using **WGSL** (WebGPU Shading L...</td>\n",
       "      <td>As of my last update in 2023, WebGPU and WGSL ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>chatgpt-4o-latest-20240903</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540924</td>\n",
       "      <td>0.459076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003aa0a76eb58c06adce6e9db59ad1da73929a431f3f23...</td>\n",
       "      <td>nêu lý do chọn đây là đề tài nghiên cứu \"Đánh...</td>\n",
       "      <td>Dưới đây là một số lý do có thể được sử dụng đ...</td>\n",
       "      <td>Chọn đề tài \"Đánh giá tác động của Social Medi...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-3.1-405b-instruct-bf16</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418697</td>\n",
       "      <td>0.581303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00448e4160ceb9578584293b6aee5d680c8e6dbbcd1d13...</td>\n",
       "      <td>package ex3_Excercise;\\n//버블정렬\\npublic class T...</td>\n",
       "      <td>```java\\npackage ex3_Excercise;\\n\\npublic clas...</td>\n",
       "      <td>```java\\npackage ex3_Excercise;\\n\\npublic clas...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>command-r-08-2024</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375706</td>\n",
       "      <td>0.624294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>ffc2a1a209a1053658645fc60dd29249392c7e0040ae5d...</td>\n",
       "      <td>Are there decent AI therapy options yet? If so...</td>\n",
       "      <td>As an AI, I cannot provide medical advice, and...</td>\n",
       "      <td>The fascinating intersection of AI and mental ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933869</td>\n",
       "      <td>0.066131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>ffd929efef61e5b353180a6e790d35896363ecf02973ee...</td>\n",
       "      <td>Imagine you have to get two goats and a cabbag...</td>\n",
       "      <td>To solve the problem of getting two goats and ...</td>\n",
       "      <td>To solve this classic problem, we'll break it ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>llama-3.1-405b-instruct-bf16</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513668</td>\n",
       "      <td>0.486332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>ffe2645c0cdb2cbbb755ad0766cfc14663726619968c4e...</td>\n",
       "      <td>翻译一下这句话：Builder Journey Experience, 优化开发者在网站及各...</td>\n",
       "      <td>Builder Journey Experience optimizes developer...</td>\n",
       "      <td>Here is a translation of the sentence:\\n\\n**Bu...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028114</td>\n",
       "      <td>0.971886</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>ffe2a8b3cf149dc4ffd040623f4c8e4e9e87b98bd41b14...</td>\n",
       "      <td>Какое программное обеспечение развернуто на Уп...</td>\n",
       "      <td>На управляющих узлах OpenShift развернуто неск...</td>\n",
       "      <td>На Управляющих узлах (Master Nodes) OpenShift ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-flash-8b-001</td>\n",
       "      <td>yi-lightning</td>\n",
       "      <td>unknown</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993996</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>fffd2ffdaa03e9e0a0cd1e8f2ee80f530bb19b08fa4312...</td>\n",
       "      <td>What is the height of the church located in Sa...</td>\n",
       "      <td>**Church Information: Église de Saint-Nazaire-...</td>\n",
       "      <td>I couldn't find any information about a church...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-3.1-70b-instruct</td>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.770465</td>\n",
       "      <td>0.229535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4839 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n",
       "1     00172aab8af10cc0648041c94a41eeab7d9caaea7717a3...   \n",
       "2     00314ee979ffc9e4e4dd3716d02c401ba117d00640a3e1...   \n",
       "3     003aa0a76eb58c06adce6e9db59ad1da73929a431f3f23...   \n",
       "4     00448e4160ceb9578584293b6aee5d680c8e6dbbcd1d13...   \n",
       "...                                                 ...   \n",
       "4834  ffc2a1a209a1053658645fc60dd29249392c7e0040ae5d...   \n",
       "4835  ffd929efef61e5b353180a6e790d35896363ecf02973ee...   \n",
       "4836  ffe2645c0cdb2cbbb755ad0766cfc14663726619968c4e...   \n",
       "4837  ffe2a8b3cf149dc4ffd040623f4c8e4e9e87b98bd41b14...   \n",
       "4838  fffd2ffdaa03e9e0a0cd1e8f2ee80f530bb19b08fa4312...   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     You will be given a piece of news. Analyze it ...   \n",
       "1                               kısaca dopamin detoksu    \n",
       "2          In Webgpu/WGSL, what are override variables?   \n",
       "3      nêu lý do chọn đây là đề tài nghiên cứu \"Đánh...   \n",
       "4     package ex3_Excercise;\\n//버블정렬\\npublic class T...   \n",
       "...                                                 ...   \n",
       "4834  Are there decent AI therapy options yet? If so...   \n",
       "4835  Imagine you have to get two goats and a cabbag...   \n",
       "4836  翻译一下这句话：Builder Journey Experience, 优化开发者在网站及各...   \n",
       "4837  Какое программное обеспечение развернуто на Уп...   \n",
       "4838  What is the height of the church located in Sa...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0     Let's break down the news and analyze it accor...   \n",
       "1     Dopamin detoksu, beyninizin dopamin seviyeleri...   \n",
       "2     In **WebGPU** using **WGSL** (WebGPU Shading L...   \n",
       "3     Dưới đây là một số lý do có thể được sử dụng đ...   \n",
       "4     ```java\\npackage ex3_Excercise;\\n\\npublic clas...   \n",
       "...                                                 ...   \n",
       "4834  As an AI, I cannot provide medical advice, and...   \n",
       "4835  To solve the problem of getting two goats and ...   \n",
       "4836  Builder Journey Experience optimizes developer...   \n",
       "4837  На управляющих узлах OpenShift развернуто неск...   \n",
       "4838  **Church Information: Église de Saint-Nazaire-...   \n",
       "\n",
       "                                             response_b   winner  \\\n",
       "0     ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a   \n",
       "1     Dopamin detoksunun amacı, aşırı uyarılmaya ned...  model_b   \n",
       "2     As of my last update in 2023, WebGPU and WGSL ...  model_a   \n",
       "3     Chọn đề tài \"Đánh giá tác động của Social Medi...  model_a   \n",
       "4     ```java\\npackage ex3_Excercise;\\n\\npublic clas...  model_a   \n",
       "...                                                 ...      ...   \n",
       "4834  The fascinating intersection of AI and mental ...  model_b   \n",
       "4835  To solve this classic problem, we'll break it ...  model_a   \n",
       "4836  Here is a translation of the sentence:\\n\\n**Bu...  model_b   \n",
       "4837  На Управляющих узлах (Master Nodes) OpenShift ...  model_a   \n",
       "4838  I couldn't find any information about a church...  model_a   \n",
       "\n",
       "                           model_a                          model_b  \\\n",
       "0                   gemma-2-27b-it             gemini-1.5-flash-002   \n",
       "1                grok-2-2024-08-13               gemini-1.5-pro-002   \n",
       "2       chatgpt-4o-latest-20240903               gpt-4-0125-preview   \n",
       "3     llama-3.1-405b-instruct-bf16               reka-core-20240904   \n",
       "4                    gemma-2-9b-it                command-r-08-2024   \n",
       "...                            ...                              ...   \n",
       "4834                 gemma-2-9b-it  llama-3.1-nemotron-70b-instruct   \n",
       "4835                       o1-mini     llama-3.1-405b-instruct-bf16   \n",
       "4836                    glm-4-plus  llama-3.1-nemotron-70b-instruct   \n",
       "4837       gemini-1.5-flash-8b-001                     yi-lightning   \n",
       "4838        llama-3.1-70b-instruct            llama-3.2-3b-instruct   \n",
       "\n",
       "        language  split        source  labels    prob_0    prob_1  prediction  \n",
       "0        Russian  valid  current_comp       0  0.865793  0.134208           0  \n",
       "1        Finnish  valid  current_comp       1  0.679179  0.320821           0  \n",
       "2        English  valid  current_comp       0  0.540924  0.459076           0  \n",
       "3     Vietnamese  valid  current_comp       0  0.418697  0.581303           1  \n",
       "4        English  valid  current_comp       0  0.375706  0.624294           1  \n",
       "...          ...    ...           ...     ...       ...       ...         ...  \n",
       "4834     English  valid  current_comp       1  0.933869  0.066131           0  \n",
       "4835     English  valid  current_comp       0  0.513668  0.486332           0  \n",
       "4836     Chinese  valid  current_comp       1  0.028114  0.971886           1  \n",
       "4837     unknown  valid  current_comp       0  0.993996  0.006004           0  \n",
       "4838     English  valid  current_comp       0  0.770465  0.229535           0  \n",
       "\n",
       "[4839 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/pseudo_labeled_final_data/oof_preds.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49121719363504857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = df['prediction'].values\n",
    "labels = df['labels'].values\n",
    "acc = accuracy_score(labels, prediction)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
