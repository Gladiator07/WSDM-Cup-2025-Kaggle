{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a96a89-e327-444a-9d2d-31aaa69e44c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游붠 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "游붠 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import tokenizer_utils\n",
    "def do_nothing(*args, **kwargs):\n",
    "    pass\n",
    "tokenizer_utils.fix_untrained_tokens = do_nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd81e4c3-b00a-4bd7-b6ed-ddc9198a2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KAGGLEHUB_CACHE\"] = \"./downloaded_kaggle\"\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"atharvaingle\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"461b0631fca2dc582a2019918b23f72d\"\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "kagglehub.competition_download(\"wsdm-cup-multilingual-chatbot-arena\")\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0273215a-77f1-423b-9526-2c8f7e19c1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00007cff95d7f7974642a785aca248b0f26e60d3312fac...</td>\n",
       "      <td>vie코 po Slovensky?</td>\n",
       "      <td>츼no, hovor칤m po slovensky. Ako v치m m칪쬰m pom칪c콘?</td>\n",
       "      <td>츼no, ve캞 som tu! M칪쬰m ti pom칪c콘 s ot치zkami al...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>Slovak</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n",
       "      <td>You will be given a piece of news. Analyze it ...</td>\n",
       "      <td>Let's break down the news and analyze it accor...</td>\n",
       "      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>Russian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  00007cff95d7f7974642a785aca248b0f26e60d3312fac...   \n",
       "1  00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                 vie코 po Slovensky?   \n",
       "1  You will be given a piece of news. Analyze it ...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0   츼no, hovor칤m po slovensky. Ako v치m m칪쬰m pom칪c콘?   \n",
       "1  Let's break down the news and analyze it accor...   \n",
       "\n",
       "                                          response_b   winner         model_a  \\\n",
       "0  츼no, ve캞 som tu! M칪쬰m ti pom칪c콘 s ot치zkami al...  model_a      o1-preview   \n",
       "1  ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a  gemma-2-27b-it   \n",
       "\n",
       "                model_b language  labels  \n",
       "0    reka-core-20240904   Slovak       0  \n",
       "1  gemini-1.5-flash-002  Russian       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"downloaded_kaggle/competitions/wsdm-cup-multilingual-chatbot-arena/train.parquet\")\n",
    "df[\"labels\"] = df[\"winner\"].map({\"model_a\": 0, \"model_b\": 1})\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec3b381-2ad4-425c-8d3c-62bbef9359ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = \"unsloth/Qwen2.5-7B-bnb-4bit\"\n",
    "ckpt = \"unsloth/Qwen2.5-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        ckpt,\n",
    "        use_fast=True,\n",
    "        trust_remote_code=True,\n",
    "        from_slow=True,\n",
    "        add_prefix_space=False,\n",
    "        padding_side=\"left\",\n",
    "        truncation_side=\"left\",\n",
    "    )\n",
    "tokenizer.add_eos_token = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6312a5-b6d7-4116-adef-1bf5800aa3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00007cff95d7f7974642a785aca248b0f26e60d3312fac...</td>\n",
       "      <td>vie코 po Slovensky?</td>\n",
       "      <td>츼no, hovor칤m po slovensky. Ako v치m m칪쬰m pom칪c콘?</td>\n",
       "      <td>츼no, ve캞 som tu! M칪쬰m ti pom칪c콘 s ot치zkami al...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>Slovak</td>\n",
       "      <td>0</td>\n",
       "      <td>## Prompt\\nvie코 po Slovensky?\\n\\n### Response ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id              prompt  \\\n",
       "0  00007cff95d7f7974642a785aca248b0f26e60d3312fac...  vie코 po Slovensky?   \n",
       "\n",
       "                                         response_a  \\\n",
       "0  츼no, hovor칤m po slovensky. Ako v치m m칪쬰m pom칪c콘?   \n",
       "\n",
       "                                          response_b   winner     model_a  \\\n",
       "0  츼no, ve캞 som tu! M칪쬰m ti pom칪c콘 s ot치zkami al...  model_a  o1-preview   \n",
       "\n",
       "              model_b language  labels  \\\n",
       "0  reka-core-20240904   Slovak       0   \n",
       "\n",
       "                                                text  \n",
       "0  ## Prompt\\nvie코 po Slovensky?\\n\\n### Response ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_text(row):\n",
    "    prompt, res_a, res_b = row[\"prompt\"], row[\"response_a\"], row[\"response_b\"]\n",
    "    text = \"## Prompt\\n\" + prompt + \"\\n\\n### Response A\\n\" + res_a + \"\\n\\n### Response B\\n\" + res_b + \"\\n\\n\" + \"## Which response is better?\"\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df.apply(prepare_text, axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aef375a-0659-48ba-91b0-8309ca419328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f3bad1-9561-4da8-91c6-cc9186db01e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd89b453aeb747aa9032f66411576d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2846a4af44a405f998e44b352e46d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'prompt', 'response_a', 'response_b', 'winner', 'model_a', 'model_b', 'language', 'labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'prompt', 'response_a', 'response_b', 'winner', 'model_a', 'model_b', 'language', 'labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df.head(5000))\n",
    "ds = ds.train_test_split(test_size=0.2, seed=42, shuffle=True)\n",
    "tok_ds = ds.map(tokenize_func, num_proc=2)\n",
    "tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c06b28a-6c75-4d32-9e5d-a6a90487711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.12.9: Fast Qwen2 patching. Transformers: 4.47.1.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.679 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "max_seq_length = 1024 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "\n",
    "\n",
    "# model_name = \"unsloth/Qwen2-7B-bnb-4bit\";load_in_4bit = True\n",
    "model_name = ckpt; load_in_4bit = True,\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,load_in_4bit = load_in_4bit,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9447f782-bd03-48e9-af50-a1f699a11d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lm_head = nn.Linear(in_features=model.config.hidden_size, out_features=2, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3761cc2b-ea38-4e6a-b2ae-389dbc372310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/unsloth/models/_utils.py:747: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  offloaded_W = torch.load(filename, map_location = \"cpu\", mmap = True)\n",
      "Unsloth 2024.12.9 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training lm_head in mixed precision to save VRAM\n",
      "trainable parameters: 29937664\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\n",
    "        # can easily be trained because it has only 2 tokens\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    modules_to_save=[\"lm_head\"]\n",
    "    # init_lora_weights = 'loftq',\n",
    "    # loftq_config = LoftQConfig(loftq_bits = 4, loftq_iter = 1), # And LoftQ\n",
    ")\n",
    "print(\"trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88eb3830-d5ee-485e-85c1-3e765b17d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aadc55d1-06bf-4459-b0e1-c426ab0239e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    logits = logits[:, -1]\n",
    "    probs = torch.from_numpy(logits).float().softmax(-1).numpy()\n",
    "    preds = probs.argmax(-1)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs = False, num_items_in_batch = None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        # print(f\"logits shape before: {logits.shape}\")\n",
    "        logits = logits[:, -1]\n",
    "        # print(f\"logits shape after last token: {logits.shape}\")\n",
    "        # print(f\"labels shape: {labels.shape}\")\n",
    "        # st_time = time.perf_counter()\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        # print(f\"time for cross_entropy calc: {time.perf_counter() - st_time}\")\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9531f1a-4d28-4bc3-a245-4be672fc8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=10,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    bf16_full_eval=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    group_by_length=True,\n",
    "    gradient_checkpointing=False,\n",
    "    torch_compile=False,\n",
    "    use_liger_kernel=False,\n",
    ")\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa12836-1d5e-43f5-a990-5cf2f8cfe4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_cols = [\"input_ids\", \"attention_mask\"]\n",
    "# sample_ds = tok_ds[\"train\"].remove_columns(column_names=[c for c in tok_ds[\"train\"].column_names if c not in keep_cols])\n",
    "# dl = torch.utils.data.DataLoader(tok_ds[\"train\"], batch_size=32, collate_fn=data_collator)\n",
    "# batch = next(iter(dl))\n",
    "# batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "# with torch.no_grad():\n",
    "#     out = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "924b2440-e399-4665-bdd6-22537168a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 4,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 32 | Gradient Accumulation steps = 1\n",
      "\\        /    Total batch size = 32 | Total steps = 125\n",
      " \"-____-\"     Number of trainable parameters = 29,937,664\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 17:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.917915</td>\n",
       "      <td>0.536000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad3fba9d-825c-4b10-8e1f-80a051eceed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_trimmed/tokenizer_config.json',\n",
       " 'lora_trimmed/special_tokens_map.json',\n",
       " 'lora_trimmed/vocab.json',\n",
       " 'lora_trimmed/merges.txt',\n",
       " 'lora_trimmed/added_tokens.json',\n",
       " 'lora_trimmed/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_trimmed\")\n",
    "tokenizer.save_pretrained(\"lora_trimmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d40cc40f-6bd3-4760-855e-296a7c86054d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_runtime': 1070.7782,\n",
       " 'train_samples_per_second': 3.736,\n",
       " 'train_steps_per_second': 0.117,\n",
       " 'total_flos': 5.568576431849472e+16,\n",
       " 'train_loss': 0.8533303833007813,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_stats.metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
