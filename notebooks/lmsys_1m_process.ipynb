{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/lmsys_1m_hf_serverless_15k.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if response_a column and response_b column is empty string then add it as failed counter\n",
    "ids = []\n",
    "for i, row in df.iterrows():\n",
    "    if row[\"response_a\"] == \"\" or row[\"response_b\"] == \"\":\n",
    "        ids.append(row[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0f40982ee5c348c2b0aafd1a03ce061b</td>\n",
       "      <td>请用python画一只猪</td>\n",
       "      <td>&lt;noinput&gt;</td>\n",
       "      <td>Here's a simple representation of a pig using ...</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>HuggingFaceH4/starchat2-15b-v0.1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41b9ee53e0f5487bbf53ec36ddc3f5ac</td>\n",
       "      <td>componha uma postagem interessante sobre geobi...</td>\n",
       "      <td>### Geobiologia: Onde a Vida e a Terra Se Enco...</td>\n",
       "      <td>A geobiologia é uma área da ciência que se con...</td>\n",
       "      <td>Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f4deae0345e644bb9d03d1fcfa0ca4a2</td>\n",
       "      <td>Beantworte die folgenden Fragen und gib bei de...</td>\n",
       "      <td>1. Ja\\n2. Ja\\n3. Ja\\n4. 6\\n5. Der Berater hat ...</td>\n",
       "      <td>1. Empathisch \\n2. Ja \\n3. Rechtschreibung und...</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7d8d4b498ded464da12405aef28b52f5</td>\n",
       "      <td>你好</td>\n",
       "      <td>你好！有什么我可以帮助您的吗？请告诉我您想要翻译成中文的文本或语言。</td>\n",
       "      <td>你好!很高兴认识你。</td>\n",
       "      <td>HuggingFaceH4/starchat2-15b-v0.1</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>834154f8744047a0bad3ea7127504509</td>\n",
       "      <td>csapcscs</td>\n",
       "      <td>I apologize, but I do not understand that inpu...</td>\n",
       "      <td>It looks like your message got a bit jumbled. ...</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>Qwen/Qwen2.5-Coder-32B-Instruct</td>\n",
       "      <td>Hungarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>80f7400bb9574978b300d31e337c9df0</td>\n",
       "      <td>Om een domeinnaam te verhuizen naar een andere...</td>\n",
       "      <td>Om een domeinnaam te verhuizen naar een andere...</td>\n",
       "      <td></td>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td></td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>d5d7f37cf8724597aa050c36070b6d18</td>\n",
       "      <td>scrivi una istruzione SQL per eliminare il rec...</td>\n",
       "      <td></td>\n",
       "      <td>Per eliminare il record con idutente uguale a ...</td>\n",
       "      <td></td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>e479f8980d2d4fdfa799b1d57e242274</td>\n",
       "      <td>你好</td>\n",
       "      <td>Hello, how can I help you today?</td>\n",
       "      <td></td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td></td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>03c3d337f0f940129dc6e4afdf553a74</td>\n",
       "      <td>en français, nommes dix façons de tuer son voi...</td>\n",
       "      <td></td>\n",
       "      <td>Je suis désolé, mais je ne peux pas répondre à...</td>\n",
       "      <td></td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>1c9e74703243438cb7c9c380000b86f1</td>\n",
       "      <td>Listázd ki a cikkben található személyek közül...</td>\n",
       "      <td></td>\n",
       "      <td>A cikkben található személyek közül azokat, ak...</td>\n",
       "      <td></td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>Hungarian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0      0f40982ee5c348c2b0aafd1a03ce061b   \n",
       "1      41b9ee53e0f5487bbf53ec36ddc3f5ac   \n",
       "2      f4deae0345e644bb9d03d1fcfa0ca4a2   \n",
       "3      7d8d4b498ded464da12405aef28b52f5   \n",
       "4      834154f8744047a0bad3ea7127504509   \n",
       "...                                 ...   \n",
       "14995  80f7400bb9574978b300d31e337c9df0   \n",
       "14996  d5d7f37cf8724597aa050c36070b6d18   \n",
       "14997  e479f8980d2d4fdfa799b1d57e242274   \n",
       "14998  03c3d337f0f940129dc6e4afdf553a74   \n",
       "14999  1c9e74703243438cb7c9c380000b86f1   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0                                           请用python画一只猪   \n",
       "1      componha uma postagem interessante sobre geobi...   \n",
       "2      Beantworte die folgenden Fragen und gib bei de...   \n",
       "3                                                     你好   \n",
       "4                                               csapcscs   \n",
       "...                                                  ...   \n",
       "14995  Om een domeinnaam te verhuizen naar een andere...   \n",
       "14996  scrivi una istruzione SQL per eliminare il rec...   \n",
       "14997                                                 你好   \n",
       "14998  en français, nommes dix façons de tuer son voi...   \n",
       "14999  Listázd ki a cikkben található személyek közül...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0                                              <noinput>   \n",
       "1      ### Geobiologia: Onde a Vida e a Terra Se Enco...   \n",
       "2      1. Ja\\n2. Ja\\n3. Ja\\n4. 6\\n5. Der Berater hat ...   \n",
       "3                     你好！有什么我可以帮助您的吗？请告诉我您想要翻译成中文的文本或语言。   \n",
       "4      I apologize, but I do not understand that inpu...   \n",
       "...                                                  ...   \n",
       "14995  Om een domeinnaam te verhuizen naar een andere...   \n",
       "14996                                                      \n",
       "14997                   Hello, how can I help you today?   \n",
       "14998                                                      \n",
       "14999                                                      \n",
       "\n",
       "                                              response_b  \\\n",
       "0      Here's a simple representation of a pig using ...   \n",
       "1      A geobiologia é uma área da ciência que se con...   \n",
       "2      1. Empathisch \\n2. Ja \\n3. Rechtschreibung und...   \n",
       "3                                             你好!很高兴认识你。   \n",
       "4      It looks like your message got a bit jumbled. ...   \n",
       "...                                                  ...   \n",
       "14995                                                      \n",
       "14996  Per eliminare il record con idutente uguale a ...   \n",
       "14997                                                      \n",
       "14998  Je suis désolé, mais je ne peux pas répondre à...   \n",
       "14999  A cikkben található személyek közül azokat, ak...   \n",
       "\n",
       "                                    model_a                           model_b  \\\n",
       "0                                alpaca-13b  HuggingFaceH4/starchat2-15b-v0.1   \n",
       "1                 Qwen/Qwen2.5-72B-Instruct                        vicuna-13b   \n",
       "2      mistralai/Mistral-Nemo-Instruct-2407                        alpaca-13b   \n",
       "3          HuggingFaceH4/starchat2-15b-v0.1                          claude-1   \n",
       "4                                  claude-1   Qwen/Qwen2.5-Coder-32B-Instruct   \n",
       "...                                     ...                               ...   \n",
       "14995                          dolly-v2-12b                                     \n",
       "14996                                                              vicuna-13b   \n",
       "14997                      oasst-pythia-12b                                     \n",
       "14998                                                              vicuna-13b   \n",
       "14999                                                        oasst-pythia-12b   \n",
       "\n",
       "         language  \n",
       "0         unknown  \n",
       "1      Portuguese  \n",
       "2          German  \n",
       "3         Chinese  \n",
       "4       Hungarian  \n",
       "...           ...  \n",
       "14995       Dutch  \n",
       "14996     Italian  \n",
       "14997     Chinese  \n",
       "14998      French  \n",
       "14999   Hungarian  \n",
       "\n",
       "[15000 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/vllm_inference_ignore_ids.pkl\", \"rb\") as f:\n",
    "    ignore_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract failed ids from ignore ids\n",
    "final_ignore_ids = set(ignore_ids) - set(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21429"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_ignore_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23419, 1990, 21429)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ignore_ids), len(ids), len(final_ignore_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/vllm_inference_ignore_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(list(final_ignore_ids), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/vllm_inference_ignore_ids.pkl\", \"rb\") as f:\n",
    "    loaded_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21429"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 7)\n",
      "(8419, 7)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "files = list(Path(\"../data/vllm_gen\").glob(\"*.parquet\"))\n",
    "hf_df = pd.read_parquet(\"../data/lmsys_1m_hf_serverless_15k.parquet\")\n",
    "hf_df.head()\n",
    "print(hf_df.shape)\n",
    "nich_df = pd.read_parquet(\"../data/hf-open-models-v1.parquet\")\n",
    "print(nich_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13010, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove empty responses columns\n",
    "hf_df = hf_df[(hf_df[\"response_a\"] != \"\") & (hf_df[\"response_b\"] != \"\")]\n",
    "hf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, (104449, 7))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for f in files:\n",
    "    data.append(pd.read_parquet(f))\n",
    "\n",
    "df = pd.concat(data)\n",
    "len(data), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0f40982ee5c348c2b0aafd1a03ce061b</td>\n",
       "      <td>请用python画一只猪</td>\n",
       "      <td>&lt;noinput&gt;</td>\n",
       "      <td>Here's a simple representation of a pig using ...</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>HuggingFaceH4/starchat2-15b-v0.1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41b9ee53e0f5487bbf53ec36ddc3f5ac</td>\n",
       "      <td>componha uma postagem interessante sobre geobi...</td>\n",
       "      <td>### Geobiologia: Onde a Vida e a Terra Se Enco...</td>\n",
       "      <td>A geobiologia é uma área da ciência que se con...</td>\n",
       "      <td>Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  0f40982ee5c348c2b0aafd1a03ce061b   \n",
       "1  41b9ee53e0f5487bbf53ec36ddc3f5ac   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                       请用python画一只猪   \n",
       "1  componha uma postagem interessante sobre geobi...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                                          <noinput>   \n",
       "1  ### Geobiologia: Onde a Vida e a Terra Se Enco...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  Here's a simple representation of a pig using ...   \n",
       "1  A geobiologia é uma área da ciência que se con...   \n",
       "\n",
       "                     model_a                           model_b    language  \n",
       "0                 alpaca-13b  HuggingFaceH4/starchat2-15b-v0.1     unknown  \n",
       "1  Qwen/Qwen2.5-72B-Instruct                        vicuna-13b  Portuguese  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>706fa28bdea948689ed037e0e36f9365</td>\n",
       "      <td>hi</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! How can I help you today? If you have a...</td>\n",
       "      <td>stablelm-tuned-alpha-7b</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc84a4d397574f6c863bcef4cd4b529f</td>\n",
       "      <td>Привет. Назови мне 10 видов оружия ближнего бо...</td>\n",
       "      <td>Привет! Вот 10 видов оружия ближнего боя с ост...</td>\n",
       "      <td>Hello! Here are ten types of edged weapons wit...</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  706fa28bdea948689ed037e0e36f9365   \n",
       "1  dc84a4d397574f6c863bcef4cd4b529f   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                                 hi   \n",
       "1  Привет. Назови мне 10 видов оружия ближнего бо...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                 Hello! How can I assist you today?   \n",
       "1  Привет! Вот 10 видов оружия ближнего боя с ост...   \n",
       "\n",
       "                                          response_b                  model_a  \\\n",
       "0  Hello! How can I help you today? If you have a...  stablelm-tuned-alpha-7b   \n",
       "1  Hello! Here are ten types of edged weapons wit...               vicuna-13b   \n",
       "\n",
       "                              model_b language  \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2  unknown  \n",
       "1  mistralai/Mistral-7B-Instruct-v0.2  Russian  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fff10fa3ca7f4ff6b25de1f8f60374fd</td>\n",
       "      <td>Законность и справедливость обработки. Персона...</td>\n",
       "      <td>Вы правильно поняли. Обработка персональных да...</td>\n",
       "      <td>В соответствии со статьей 8 Федерального закон...</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ffed5c2c2bc24dacb9eeb106d00010b3</td>\n",
       "      <td>\"\"衛生兵\"\"のことを英語では何といいますか？</td>\n",
       "      <td>\"衛生兵\"という言葉は、軍隊内で医療支援や傷病兵の治療・救護に携わる役割を担う兵士のことだと...</td>\n",
       "      <td>The term \"衛生兵\" in English is typically transl...</td>\n",
       "      <td>Qwen/QwQ-32B-Preview</td>\n",
       "      <td>mistralai/Mixtral-8x7B-Instruct-v0.1</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  fff10fa3ca7f4ff6b25de1f8f60374fd   \n",
       "1  ffed5c2c2bc24dacb9eeb106d00010b3   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Законность и справедливость обработки. Персона...   \n",
       "1                            \"\"衛生兵\"\"のことを英語では何といいますか？   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  Вы правильно поняли. Обработка персональных да...   \n",
       "1  \"衛生兵\"という言葉は、軍隊内で医療支援や傷病兵の治療・救護に携わる役割を担う兵士のことだと...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  В соответствии со статьей 8 Федерального закон...   \n",
       "1   The term \"衛生兵\" in English is typically transl...   \n",
       "\n",
       "                              model_a                               model_b  \\\n",
       "0  mistralai/Mistral-7B-Instruct-v0.3  mistralai/Mistral-Nemo-Instruct-2407   \n",
       "1                Qwen/QwQ-32B-Preview  mistralai/Mixtral-8x7B-Instruct-v0.1   \n",
       "\n",
       "   language  \n",
       "0   Russian  \n",
       "1  Japanese  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nich_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125878, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([hf_df, df, nich_df])\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0f40982ee5c348c2b0aafd1a03ce061b</td>\n",
       "      <td>请用python画一只猪</td>\n",
       "      <td>&lt;noinput&gt;</td>\n",
       "      <td>Here's a simple representation of a pig using ...</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>HuggingFaceH4/starchat2-15b-v0.1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41b9ee53e0f5487bbf53ec36ddc3f5ac</td>\n",
       "      <td>componha uma postagem interessante sobre geobi...</td>\n",
       "      <td>### Geobiologia: Onde a Vida e a Terra Se Enco...</td>\n",
       "      <td>A geobiologia é uma área da ciência que se con...</td>\n",
       "      <td>Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  0f40982ee5c348c2b0aafd1a03ce061b   \n",
       "1  41b9ee53e0f5487bbf53ec36ddc3f5ac   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                       请用python画一只猪   \n",
       "1  componha uma postagem interessante sobre geobi...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                                          <noinput>   \n",
       "1  ### Geobiologia: Onde a Vida e a Terra Se Enco...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  Here's a simple representation of a pig using ...   \n",
       "1  A geobiologia é uma área da ciência que se con...   \n",
       "\n",
       "                     model_a                           model_b    language  \n",
       "0                 alpaca-13b  HuggingFaceH4/starchat2-15b-v0.1     unknown  \n",
       "1  Qwen/Qwen2.5-72B-Instruct                        vicuna-13b  Portuguese  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 7)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for empty responses\n",
    "final_df[(final_df[\"response_a\"] == \"\") | (final_df[\"response_b\"] == \"\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_parquet(\"../data/lmsys1m_multilingual_single_turn_unlabeled.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Chinese': 19434,\n",
       "         'Russian': 14982,\n",
       "         'Portuguese': 14678,\n",
       "         'unknown': 12858,\n",
       "         'Spanish': 11683,\n",
       "         'French': 8984,\n",
       "         'German': 8902,\n",
       "         'Italian': 7193,\n",
       "         'Japanese': 4678,\n",
       "         'Korean': 2995,\n",
       "         'Polish': 1934,\n",
       "         'Indonesian': 1357,\n",
       "         'Arabic': 1240,\n",
       "         'Turkish': 963,\n",
       "         'Vietnamese': 911,\n",
       "         'English': 883,\n",
       "         'Dutch': 685,\n",
       "         'Ukrainian': 683,\n",
       "         'Latin': 682,\n",
       "         'Greek': 668,\n",
       "         'Danish': 667,\n",
       "         'Persian': 520,\n",
       "         'Hungarian': 436,\n",
       "         'Czech': 421,\n",
       "         'Swedish': 353,\n",
       "         'Romanian': 306,\n",
       "         'Serbian': 294,\n",
       "         'Corsican': 281,\n",
       "         'Hebrew': 265,\n",
       "         'Thai': 262,\n",
       "         'Finnish': 261,\n",
       "         'Slovak': 260,\n",
       "         'Galician': 254,\n",
       "         'Scots': 253,\n",
       "         'Bulgarian': 250,\n",
       "         'Malay': 249,\n",
       "         'Hawaiian': 218,\n",
       "         'Norwegian': 202,\n",
       "         'Catalan': 196,\n",
       "         'Norwegian Nynorsk': 136,\n",
       "         'Esperanto': 114,\n",
       "         'Afrikaans': 99,\n",
       "         'Occitan': 98,\n",
       "         'Macedonian': 89,\n",
       "         'Guarani': 83,\n",
       "         'Tsonga': 82,\n",
       "         'Bangla': 79,\n",
       "         'Slovenian': 69,\n",
       "         'Croatian': 69,\n",
       "         'Somali': 67,\n",
       "         'Uzbek': 67,\n",
       "         'Swahili': 62,\n",
       "         'Tongan': 62,\n",
       "         'Quechua': 61,\n",
       "         'Xhosa': 61,\n",
       "         'Interlingue': 60,\n",
       "         'Hindi': 58,\n",
       "         'Breton': 57,\n",
       "         'Kinyarwanda': 56,\n",
       "         'Samoan': 56,\n",
       "         'Manx': 56,\n",
       "         'Sanskrit': 53,\n",
       "         'Seselwa Creole French': 52,\n",
       "         'Malagasy': 52,\n",
       "         'Luxembourgish': 50,\n",
       "         'Basque': 50,\n",
       "         'Oromo': 49,\n",
       "         'Volapük': 48,\n",
       "         'Estonian': 47,\n",
       "         'Tatar': 47,\n",
       "         'Scottish Gaelic': 46,\n",
       "         'Haitian Creole': 45,\n",
       "         'Tswana': 44,\n",
       "         'Lithuanian': 44,\n",
       "         'Bosnian': 44,\n",
       "         'Latvian': 43,\n",
       "         'Interlingua': 42,\n",
       "         'Waray': 40,\n",
       "         'Tagalog': 40,\n",
       "         'Romansh': 40,\n",
       "         'zzp': 39,\n",
       "         'Faroese': 39,\n",
       "         'Welsh': 38,\n",
       "         'Wolof': 35,\n",
       "         'Irish': 34,\n",
       "         'Aymara': 30,\n",
       "         'Afar': 30,\n",
       "         'Icelandic': 29,\n",
       "         'Māori': 28,\n",
       "         'Azerbaijani': 28,\n",
       "         'Khasi': 27,\n",
       "         'Klingon': 27,\n",
       "         'Bislama': 26,\n",
       "         'Maltese': 26,\n",
       "         'Lingala': 25,\n",
       "         'Southern Sotho': 25,\n",
       "         'Javanese': 24,\n",
       "         'Albanian': 24,\n",
       "         'Western Frisian': 23,\n",
       "         'Kalaallisut': 22,\n",
       "         'Nauru': 22,\n",
       "         'Hmong': 21,\n",
       "         'Hausa': 21,\n",
       "         'Morisyen': 21,\n",
       "         'Akan': 20,\n",
       "         'Sundanese': 18,\n",
       "         'Belarusian': 18,\n",
       "         'Ganda': 17,\n",
       "         'Cebuano': 17,\n",
       "         'Zhuang': 17,\n",
       "         'Kazakh': 16,\n",
       "         'Turkmen': 16,\n",
       "         'Shona': 15,\n",
       "         'Fijian': 14,\n",
       "         'Nyanja': 12,\n",
       "         'Tajik': 11,\n",
       "         'Amharic': 11,\n",
       "         'Tamil': 10,\n",
       "         'Rundi': 9,\n",
       "         'Sinhala': 9,\n",
       "         'Igbo': 8,\n",
       "         'xx': 8,\n",
       "         'Mongolian': 8,\n",
       "         'Armenian': 8,\n",
       "         'Uyghur': 7,\n",
       "         'Northern Sotho': 7,\n",
       "         'Cherokee': 7,\n",
       "         'Burmese': 6,\n",
       "         'Yoruba': 6,\n",
       "         'Venda': 5,\n",
       "         'Kurdish': 5,\n",
       "         'Urdu': 5,\n",
       "         'Lao': 5,\n",
       "         'Zulu': 5,\n",
       "         'Bashkir': 4,\n",
       "         'Swati': 4,\n",
       "         'Kyrgyz': 4,\n",
       "         'Pashto': 3,\n",
       "         'Marathi': 3,\n",
       "         'Sindhi': 3,\n",
       "         'Punjabi': 3,\n",
       "         'Nepali': 3,\n",
       "         'Sango': 2,\n",
       "         'Yiddish': 2,\n",
       "         'Kannada': 2,\n",
       "         'Malayalam': 1,\n",
       "         'Abkhazian': 1,\n",
       "         'Inupiaq': 1})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(final_df[\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'vicuna-13b': 54006,\n",
       "         'alpaca-13b': 10750,\n",
       "         'meta-llama/Meta-Llama-3-8B-Instruct': 8633,\n",
       "         'mistralai/Mistral-7B-Instruct-v0.3': 8416,\n",
       "         'allenai/Llama-3.1-Tulu-3-8B': 7103,\n",
       "         'Qwen/Qwen2.5-7B-Instruct': 7086,\n",
       "         'meta-llama/Llama-3.1-8B-Instruct': 7041,\n",
       "         'Qwen/Qwen2-1.5B-Instruct': 7037,\n",
       "         'microsoft/Phi-3-mini-4k-instruct': 6999,\n",
       "         'google/gemma-2-9b-it': 6993,\n",
       "         'Qwen/Qwen2.5-14B-Instruct-AWQ': 6971,\n",
       "         'mistralai/Mistral-7B-Instruct-v0.2': 6967,\n",
       "         'Nexusflow/Starling-LM-7B-beta': 6941,\n",
       "         'google/gemma-2-2b-it': 6917,\n",
       "         'meta-llama/Llama-3.2-3B-Instruct': 6905,\n",
       "         'Qwen/Qwen2.5-3B-Instruct': 6800,\n",
       "         'Qwen/Qwen2-7B-Instruct': 6766,\n",
       "         'chatglm-6b': 6706,\n",
       "         'koala-13b': 6457,\n",
       "         'claude-1': 5152,\n",
       "         'llama-2-13b-chat': 4250,\n",
       "         'llama-13b': 3624,\n",
       "         'mistralai/Mistral-Nemo-Instruct-2407': 3562,\n",
       "         'vicuna-33b': 3435,\n",
       "         'meta-llama/Llama-3.3-70B-Instruct': 3010,\n",
       "         'mistralai/Mixtral-8x7B-Instruct-v0.1': 2995,\n",
       "         'Qwen/Qwen2.5-72B-Instruct': 2927,\n",
       "         '01-ai/Yi-1.5-34B-Chat': 2918,\n",
       "         'HuggingFaceH4/starchat2-15b-v0.1': 2909,\n",
       "         'fastchat-t5-3b': 2887,\n",
       "         'oasst-pythia-12b': 2819,\n",
       "         'dolly-v2-12b': 2670,\n",
       "         'RWKV-4-Raven-14B': 2019,\n",
       "         'vicuna-7b': 1751,\n",
       "         'Qwen/Qwen2.5-Coder-32B-Instruct': 1695,\n",
       "         'meta-llama/Llama-3.1-70B-Instruct': 1657,\n",
       "         'guanaco-33b': 1546,\n",
       "         'stablelm-tuned-alpha-7b': 1528,\n",
       "         'mpt-7b-chat': 1444,\n",
       "         'NousResearch/Hermes-3-Llama-3.1-8B': 1408,\n",
       "         'microsoft/Phi-3.5-mini-instruct': 1294,\n",
       "         'gpt4all-13b-snoozy': 1276,\n",
       "         'google/gemma-2-27b-it': 1230,\n",
       "         'wizardlm-13b': 1176,\n",
       "         'Qwen/QwQ-32B-Preview': 1117,\n",
       "         'mpt-30b-chat': 895,\n",
       "         'gpt-3.5-turbo': 672,\n",
       "         'palm-2': 578,\n",
       "         'gpt-4': 578,\n",
       "         'claude-instant-1': 532,\n",
       "         'llama-2-7b-chat': 498,\n",
       "         'claude-2': 210})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(final_df[\"model_a\"].tolist() + final_df[\"model_b\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0f40982ee5c348c2b0aafd1a03ce061b</td>\n",
       "      <td>请用python画一只猪</td>\n",
       "      <td>&lt;noinput&gt;</td>\n",
       "      <td>Here's a simple representation of a pig using ...</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>HuggingFaceH4/starchat2-15b-v0.1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41b9ee53e0f5487bbf53ec36ddc3f5ac</td>\n",
       "      <td>componha uma postagem interessante sobre geobi...</td>\n",
       "      <td>### Geobiologia: Onde a Vida e a Terra Se Enco...</td>\n",
       "      <td>A geobiologia é uma área da ciência que se con...</td>\n",
       "      <td>Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f4deae0345e644bb9d03d1fcfa0ca4a2</td>\n",
       "      <td>Beantworte die folgenden Fragen und gib bei de...</td>\n",
       "      <td>1. Ja\\n2. Ja\\n3. Ja\\n4. 6\\n5. Der Berater hat ...</td>\n",
       "      <td>1. Empathisch \\n2. Ja \\n3. Rechtschreibung und...</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7d8d4b498ded464da12405aef28b52f5</td>\n",
       "      <td>你好</td>\n",
       "      <td>你好！有什么我可以帮助您的吗？请告诉我您想要翻译成中文的文本或语言。</td>\n",
       "      <td>你好!很高兴认识你。</td>\n",
       "      <td>HuggingFaceH4/starchat2-15b-v0.1</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>834154f8744047a0bad3ea7127504509</td>\n",
       "      <td>csapcscs</td>\n",
       "      <td>I apologize, but I do not understand that inpu...</td>\n",
       "      <td>It looks like your message got a bit jumbled. ...</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>Qwen/Qwen2.5-Coder-32B-Instruct</td>\n",
       "      <td>Hungarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8414</th>\n",
       "      <td>00215ddd43f94a62884f2887e6fc9e2c</td>\n",
       "      <td>Your task is to generate a short summary of a ...</td>\n",
       "      <td>On January 26, 2023, the reviewer purchased a ...</td>\n",
       "      <td>Title: Unsatisfactory Boot Purchase\\n\\nSummary...</td>\n",
       "      <td>01-ai/Yi-1.5-34B-Chat</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8415</th>\n",
       "      <td>000f9a1f719045be9041935aa039bfd4</td>\n",
       "      <td>привет</td>\n",
       "      <td>Привет! Как я могу помочь вам сегодня?</td>\n",
       "      <td>Здравствуй! Как дела? В чем я могу тебе помоч...</td>\n",
       "      <td>NousResearch/Hermes-3-Llama-3.1-8B</td>\n",
       "      <td>mistralai/Mixtral-8x7B-Instruct-v0.1</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>000e2ddeb641444fa75c01313466e5ef</td>\n",
       "      <td>Напиши речь выпускников в университете факульт...</td>\n",
       "      <td>Привет всем! Сначала хочу сказать, как я рада ...</td>\n",
       "      <td>Here's a possible speech for graduating studen...</td>\n",
       "      <td>Qwen/QwQ-32B-Preview</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>00094c0097564782a96b602ae56787fa</td>\n",
       "      <td>Qui est le plus grand génie entre Tesla et Edi...</td>\n",
       "      <td>Une question qui a suscité de nombreux débats!...</td>\n",
       "      <td>Une question classique qui a suscité de nombre...</td>\n",
       "      <td>meta-llama/Llama-3.3-70B-Instruct</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>0008d955c9ef42f5b6fcc03b11ca028c</td>\n",
       "      <td>Придумай новость стиле российского телевидения...</td>\n",
       "      <td>**Гороскоп дня:** Мужчина оберегает удивительн...</td>\n",
       "      <td>\"Внимание, экстренный репортаж! Сегодня в цент...</td>\n",
       "      <td>01-ai/Yi-1.5-34B-Chat</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125878 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0     0f40982ee5c348c2b0aafd1a03ce061b   \n",
       "1     41b9ee53e0f5487bbf53ec36ddc3f5ac   \n",
       "2     f4deae0345e644bb9d03d1fcfa0ca4a2   \n",
       "3     7d8d4b498ded464da12405aef28b52f5   \n",
       "4     834154f8744047a0bad3ea7127504509   \n",
       "...                                ...   \n",
       "8414  00215ddd43f94a62884f2887e6fc9e2c   \n",
       "8415  000f9a1f719045be9041935aa039bfd4   \n",
       "8416  000e2ddeb641444fa75c01313466e5ef   \n",
       "8417  00094c0097564782a96b602ae56787fa   \n",
       "8418  0008d955c9ef42f5b6fcc03b11ca028c   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0                                          请用python画一只猪   \n",
       "1     componha uma postagem interessante sobre geobi...   \n",
       "2     Beantworte die folgenden Fragen und gib bei de...   \n",
       "3                                                    你好   \n",
       "4                                              csapcscs   \n",
       "...                                                 ...   \n",
       "8414  Your task is to generate a short summary of a ...   \n",
       "8415                                             привет   \n",
       "8416  Напиши речь выпускников в университете факульт...   \n",
       "8417  Qui est le plus grand génie entre Tesla et Edi...   \n",
       "8418  Придумай новость стиле российского телевидения...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0                                             <noinput>   \n",
       "1     ### Geobiologia: Onde a Vida e a Terra Se Enco...   \n",
       "2     1. Ja\\n2. Ja\\n3. Ja\\n4. 6\\n5. Der Berater hat ...   \n",
       "3                    你好！有什么我可以帮助您的吗？请告诉我您想要翻译成中文的文本或语言。   \n",
       "4     I apologize, but I do not understand that inpu...   \n",
       "...                                                 ...   \n",
       "8414  On January 26, 2023, the reviewer purchased a ...   \n",
       "8415             Привет! Как я могу помочь вам сегодня?   \n",
       "8416  Привет всем! Сначала хочу сказать, как я рада ...   \n",
       "8417  Une question qui a suscité de nombreux débats!...   \n",
       "8418  **Гороскоп дня:** Мужчина оберегает удивительн...   \n",
       "\n",
       "                                             response_b  \\\n",
       "0     Here's a simple representation of a pig using ...   \n",
       "1     A geobiologia é uma área da ciência que se con...   \n",
       "2     1. Empathisch \\n2. Ja \\n3. Rechtschreibung und...   \n",
       "3                                            你好!很高兴认识你。   \n",
       "4     It looks like your message got a bit jumbled. ...   \n",
       "...                                                 ...   \n",
       "8414  Title: Unsatisfactory Boot Purchase\\n\\nSummary...   \n",
       "8415   Здравствуй! Как дела? В чем я могу тебе помоч...   \n",
       "8416  Here's a possible speech for graduating studen...   \n",
       "8417  Une question classique qui a suscité de nombre...   \n",
       "8418  \"Внимание, экстренный репортаж! Сегодня в цент...   \n",
       "\n",
       "                                   model_a  \\\n",
       "0                               alpaca-13b   \n",
       "1                Qwen/Qwen2.5-72B-Instruct   \n",
       "2     mistralai/Mistral-Nemo-Instruct-2407   \n",
       "3         HuggingFaceH4/starchat2-15b-v0.1   \n",
       "4                                 claude-1   \n",
       "...                                    ...   \n",
       "8414                 01-ai/Yi-1.5-34B-Chat   \n",
       "8415    NousResearch/Hermes-3-Llama-3.1-8B   \n",
       "8416                  Qwen/QwQ-32B-Preview   \n",
       "8417     meta-llama/Llama-3.3-70B-Instruct   \n",
       "8418                 01-ai/Yi-1.5-34B-Chat   \n",
       "\n",
       "                                   model_b    language  \n",
       "0         HuggingFaceH4/starchat2-15b-v0.1     unknown  \n",
       "1                               vicuna-13b  Portuguese  \n",
       "2                               alpaca-13b      German  \n",
       "3                                 claude-1     Chinese  \n",
       "4          Qwen/Qwen2.5-Coder-32B-Instruct   Hungarian  \n",
       "...                                    ...         ...  \n",
       "8414    mistralai/Mistral-7B-Instruct-v0.3     Italian  \n",
       "8415  mistralai/Mixtral-8x7B-Instruct-v0.1     Russian  \n",
       "8416   meta-llama/Meta-Llama-3-8B-Instruct     Russian  \n",
       "8417   meta-llama/Meta-Llama-3-8B-Instruct      French  \n",
       "8418  mistralai/Mistral-Nemo-Instruct-2407     Russian  \n",
       "\n",
       "[125878 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'请用python画一只猪'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../data/train_combined_stage_1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106064, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231942"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "125878 + 106064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>winner</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8b8a298a65a4169963967da44c5b05b</td>\n",
       "      <td>crie uma programa em html, js, cs,  que solici...</td>\n",
       "      <td>Aqui está um exemplo de como você pode criar u...</td>\n",
       "      <td>Aqui está um programa em HTML, JavaScript e CS...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[0.26953125, 0.78515625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dfbc4eeb6624cdd929cabeeb6f99d26</td>\n",
       "      <td>Erzähle mir eine lustige aber lehrreiche Kurzg...</td>\n",
       "      <td>### Eine lustige und lehrreiche Kurzgeschichte...</td>\n",
       "      <td>Es war einmal ein junges, sprechendes Ferkel n...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>German</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[0.74609375, 0.6796875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7e67947c57c643be8d2d4439d97b2519</td>\n",
       "      <td>Ik wil een recept voor baklava</td>\n",
       "      <td>Hier is een basisrecept voor baklava, een klas...</td>\n",
       "      <td>Baklava is een traditionele gestoomde taart ui...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.3984375, 1.6328125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d348b6c4b75747b1a6cef2d676d6e971</td>\n",
       "      <td>Сделай кратки анализ всех аэропортов Шри-Ланки...</td>\n",
       "      <td>Аэропорт \"Белгийский аэропорт\" - британский аэ...</td>\n",
       "      <td>Анализ аэропортов Шри-Ланки:\\n\\n1.  **Больница...</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>Russian</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[1.0859375, 0.322265625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e1c479a622b540b39fcff3a61822c754</td>\n",
       "      <td>Создай сайт визитку, подобного примеру (https:...</td>\n",
       "      <td>I'd be happy to help you create a website for ...</td>\n",
       "      <td>Вот код страницы и таблицы стилей, учитывающий...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Russian</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[0.10888671875, 0.87109375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125873</th>\n",
       "      <td>646ef0b0fda143cdb89cd32ed18c940c</td>\n",
       "      <td>bom dia</td>\n",
       "      <td>Bom dia!</td>\n",
       "      <td></td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>microsoft/Phi-3.5-mini-instruct</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[2.34375, -1.15625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125874</th>\n",
       "      <td>2a272049f63c4722b426a32eda916b57</td>\n",
       "      <td>测试</td>\n",
       "      <td>测试</td>\n",
       "      <td>你好。</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.1083984375, 0.98046875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125875</th>\n",
       "      <td>534e6da0e64244d4a44128f151ade350</td>\n",
       "      <td>今天</td>\n",
       "      <td>今天。</td>\n",
       "      <td>,</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[1.546875, -0.37890625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125876</th>\n",
       "      <td>f4f9ee96a26b479a99e7ddc585685c15</td>\n",
       "      <td>سلام</td>\n",
       "      <td>سلام!</td>\n",
       "      <td>خوب</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>microsoft/Phi-3-mini-4k-instruct</td>\n",
       "      <td>Persian</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[0.4609375, 0.4609375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125877</th>\n",
       "      <td>31a8c80814474ff9848d97a913c5e54f</td>\n",
       "      <td>嗯</td>\n",
       "      <td>​</td>\n",
       "      <td>😊</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.486328125, 1.34375]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125878 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0       d8b8a298a65a4169963967da44c5b05b   \n",
       "1       6dfbc4eeb6624cdd929cabeeb6f99d26   \n",
       "2       7e67947c57c643be8d2d4439d97b2519   \n",
       "3       d348b6c4b75747b1a6cef2d676d6e971   \n",
       "4       e1c479a622b540b39fcff3a61822c754   \n",
       "...                                  ...   \n",
       "125873  646ef0b0fda143cdb89cd32ed18c940c   \n",
       "125874  2a272049f63c4722b426a32eda916b57   \n",
       "125875  534e6da0e64244d4a44128f151ade350   \n",
       "125876  f4f9ee96a26b479a99e7ddc585685c15   \n",
       "125877  31a8c80814474ff9848d97a913c5e54f   \n",
       "\n",
       "                                                   prompt  \\\n",
       "0       crie uma programa em html, js, cs,  que solici...   \n",
       "1       Erzähle mir eine lustige aber lehrreiche Kurzg...   \n",
       "2                          Ik wil een recept voor baklava   \n",
       "3       Сделай кратки анализ всех аэропортов Шри-Ланки...   \n",
       "4       Создай сайт визитку, подобного примеру (https:...   \n",
       "...                                                   ...   \n",
       "125873                                            bom dia   \n",
       "125874                                                 测试   \n",
       "125875                                                 今天   \n",
       "125876                                               سلام   \n",
       "125877                                                  嗯   \n",
       "\n",
       "                                               response_a  \\\n",
       "0       Aqui está um exemplo de como você pode criar u...   \n",
       "1       ### Eine lustige und lehrreiche Kurzgeschichte...   \n",
       "2       Hier is een basisrecept voor baklava, een klas...   \n",
       "3       Аэропорт \"Белгийский аэропорт\" - британский аэ...   \n",
       "4       I'd be happy to help you create a website for ...   \n",
       "...                                                   ...   \n",
       "125873                                           Bom dia!   \n",
       "125874                                                 测试   \n",
       "125875                                                今天。   \n",
       "125876                                              سلام!   \n",
       "125877                                                  ​   \n",
       "\n",
       "                                               response_b  \\\n",
       "0       Aqui está um programa em HTML, JavaScript e CS...   \n",
       "1       Es war einmal ein junges, sprechendes Ferkel n...   \n",
       "2       Baklava is een traditionele gestoomde taart ui...   \n",
       "3       Анализ аэропортов Шри-Ланки:\\n\\n1.  **Больница...   \n",
       "4       Вот код страницы и таблицы стилей, учитывающий...   \n",
       "...                                                   ...   \n",
       "125873                                                      \n",
       "125874                                                你好。   \n",
       "125875                                                  ,   \n",
       "125876                                                خوب   \n",
       "125877                                                  😊   \n",
       "\n",
       "                                    model_a  \\\n",
       "0       meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "1                  Qwen/Qwen2.5-3B-Instruct   \n",
       "2                  Qwen/Qwen2.5-3B-Instruct   \n",
       "3                          oasst-pythia-12b   \n",
       "4       meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "...                                     ...   \n",
       "125873  meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "125874                           alpaca-13b   \n",
       "125875     meta-llama/Llama-3.1-8B-Instruct   \n",
       "125876                           chatglm-6b   \n",
       "125877                           vicuna-13b   \n",
       "\n",
       "                                     model_b    language   winner  \\\n",
       "0       mistralai/Mistral-Nemo-Instruct-2407  Portuguese  model_b   \n",
       "1                                 vicuna-13b      German  model_a   \n",
       "2                                 vicuna-13b       Dutch  model_b   \n",
       "3           meta-llama/Llama-3.1-8B-Instruct     Russian  model_a   \n",
       "4       mistralai/Mistral-Nemo-Instruct-2407     Russian  model_b   \n",
       "...                                      ...         ...      ...   \n",
       "125873       microsoft/Phi-3.5-mini-instruct  Portuguese  model_a   \n",
       "125874     meta-llama/Llama-3.1-70B-Instruct     Chinese  model_b   \n",
       "125875                        fastchat-t5-3b    Japanese  model_a   \n",
       "125876      microsoft/Phi-3-mini-4k-instruct     Persian  model_a   \n",
       "125877   meta-llama/Meta-Llama-3-8B-Instruct     Chinese  model_b   \n",
       "\n",
       "                             logits  \n",
       "0          [0.26953125, 0.78515625]  \n",
       "1           [0.74609375, 0.6796875]  \n",
       "2           [-0.3984375, 1.6328125]  \n",
       "3          [1.0859375, 0.322265625]  \n",
       "4       [0.10888671875, 0.87109375]  \n",
       "...                             ...  \n",
       "125873          [2.34375, -1.15625]  \n",
       "125874  [-0.1083984375, 0.98046875]  \n",
       "125875      [1.546875, -0.37890625]  \n",
       "125876       [0.4609375, 0.4609375]  \n",
       "125877      [-0.486328125, 1.34375]  \n",
       "\n",
       "[125878 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../data/lmsys1m_110k_pseudo_label_gemma2stage1.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>logits</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n",
       "      <td>You will be given a piece of news. Analyze it ...</td>\n",
       "      <td>Let's break down the news and analyze it accor...</td>\n",
       "      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>Russian</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[1.4453125, -0.349609375]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00172aab8af10cc0648041c94a41eeab7d9caaea7717a3...</td>\n",
       "      <td>kısaca dopamin detoksu</td>\n",
       "      <td>Dopamin detoksu, beyninizin dopamin seviyeleri...</td>\n",
       "      <td>Dopamin detoksunun amacı, aşırı uyarılmaya ned...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>grok-2-2024-08-13</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.70703125, 0.25390625]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00314ee979ffc9e4e4dd3716d02c401ba117d00640a3e1...</td>\n",
       "      <td>In Webgpu/WGSL, what are override variables?</td>\n",
       "      <td>In **WebGPU** using **WGSL** (WebGPU Shading L...</td>\n",
       "      <td>As of my last update in 2023, WebGPU and WGSL ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>chatgpt-4o-latest-20240903</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[1.1953125, -0.138671875]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003aa0a76eb58c06adce6e9db59ad1da73929a431f3f23...</td>\n",
       "      <td>nêu lý do chọn đây là đề tài nghiên cứu \"Đánh...</td>\n",
       "      <td>Dưới đây là một số lý do có thể được sử dụng đ...</td>\n",
       "      <td>Chọn đề tài \"Đánh giá tác động của Social Medi...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-3.1-405b-instruct-bf16</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.5234375, 0.34375]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00448e4160ceb9578584293b6aee5d680c8e6dbbcd1d13...</td>\n",
       "      <td>package ex3_Excercise;\\n//버블정렬\\npublic class T...</td>\n",
       "      <td>```java\\npackage ex3_Excercise;\\n\\npublic clas...</td>\n",
       "      <td>```java\\npackage ex3_Excercise;\\n\\npublic clas...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>command-r-08-2024</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.90234375, 0.045654296875]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>ffc2a1a209a1053658645fc60dd29249392c7e0040ae5d...</td>\n",
       "      <td>Are there decent AI therapy options yet? If so...</td>\n",
       "      <td>As an AI, I cannot provide medical advice, and...</td>\n",
       "      <td>The fascinating intersection of AI and mental ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[-1.609375, 2.28125]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>ffd929efef61e5b353180a6e790d35896363ecf02973ee...</td>\n",
       "      <td>Imagine you have to get two goats and a cabbag...</td>\n",
       "      <td>To solve the problem of getting two goats and ...</td>\n",
       "      <td>To solve this classic problem, we'll break it ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>llama-3.1-405b-instruct-bf16</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[1.1015625, -0.07373046875]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>ffe2645c0cdb2cbbb755ad0766cfc14663726619968c4e...</td>\n",
       "      <td>翻译一下这句话：Builder Journey Experience, 优化开发者在网站及各...</td>\n",
       "      <td>Builder Journey Experience optimizes developer...</td>\n",
       "      <td>Here is a translation of the sentence:\\n\\n**Bu...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[-0.1591796875, 0.94921875]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>ffe2a8b3cf149dc4ffd040623f4c8e4e9e87b98bd41b14...</td>\n",
       "      <td>Какое программное обеспечение развернуто на Уп...</td>\n",
       "      <td>На управляющих узлах OpenShift развернуто неск...</td>\n",
       "      <td>На Управляющих узлах (Master Nodes) OpenShift ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-flash-8b-001</td>\n",
       "      <td>yi-lightning</td>\n",
       "      <td>unknown</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[-0.0213623046875, 0.796875]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>fffd2ffdaa03e9e0a0cd1e8f2ee80f530bb19b08fa4312...</td>\n",
       "      <td>What is the height of the church located in Sa...</td>\n",
       "      <td>**Church Information: Église de Saint-Nazaire-...</td>\n",
       "      <td>I couldn't find any information about a church...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-3.1-70b-instruct</td>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.53515625, 0.47265625]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4839 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n",
       "1     00172aab8af10cc0648041c94a41eeab7d9caaea7717a3...   \n",
       "2     00314ee979ffc9e4e4dd3716d02c401ba117d00640a3e1...   \n",
       "3     003aa0a76eb58c06adce6e9db59ad1da73929a431f3f23...   \n",
       "4     00448e4160ceb9578584293b6aee5d680c8e6dbbcd1d13...   \n",
       "...                                                 ...   \n",
       "4834  ffc2a1a209a1053658645fc60dd29249392c7e0040ae5d...   \n",
       "4835  ffd929efef61e5b353180a6e790d35896363ecf02973ee...   \n",
       "4836  ffe2645c0cdb2cbbb755ad0766cfc14663726619968c4e...   \n",
       "4837  ffe2a8b3cf149dc4ffd040623f4c8e4e9e87b98bd41b14...   \n",
       "4838  fffd2ffdaa03e9e0a0cd1e8f2ee80f530bb19b08fa4312...   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     You will be given a piece of news. Analyze it ...   \n",
       "1                               kısaca dopamin detoksu    \n",
       "2          In Webgpu/WGSL, what are override variables?   \n",
       "3      nêu lý do chọn đây là đề tài nghiên cứu \"Đánh...   \n",
       "4     package ex3_Excercise;\\n//버블정렬\\npublic class T...   \n",
       "...                                                 ...   \n",
       "4834  Are there decent AI therapy options yet? If so...   \n",
       "4835  Imagine you have to get two goats and a cabbag...   \n",
       "4836  翻译一下这句话：Builder Journey Experience, 优化开发者在网站及各...   \n",
       "4837  Какое программное обеспечение развернуто на Уп...   \n",
       "4838  What is the height of the church located in Sa...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0     Let's break down the news and analyze it accor...   \n",
       "1     Dopamin detoksu, beyninizin dopamin seviyeleri...   \n",
       "2     In **WebGPU** using **WGSL** (WebGPU Shading L...   \n",
       "3     Dưới đây là một số lý do có thể được sử dụng đ...   \n",
       "4     ```java\\npackage ex3_Excercise;\\n\\npublic clas...   \n",
       "...                                                 ...   \n",
       "4834  As an AI, I cannot provide medical advice, and...   \n",
       "4835  To solve the problem of getting two goats and ...   \n",
       "4836  Builder Journey Experience optimizes developer...   \n",
       "4837  На управляющих узлах OpenShift развернуто неск...   \n",
       "4838  **Church Information: Église de Saint-Nazaire-...   \n",
       "\n",
       "                                             response_b   winner  \\\n",
       "0     ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a   \n",
       "1     Dopamin detoksunun amacı, aşırı uyarılmaya ned...  model_b   \n",
       "2     As of my last update in 2023, WebGPU and WGSL ...  model_a   \n",
       "3     Chọn đề tài \"Đánh giá tác động của Social Medi...  model_a   \n",
       "4     ```java\\npackage ex3_Excercise;\\n\\npublic clas...  model_a   \n",
       "...                                                 ...      ...   \n",
       "4834  The fascinating intersection of AI and mental ...  model_b   \n",
       "4835  To solve this classic problem, we'll break it ...  model_a   \n",
       "4836  Here is a translation of the sentence:\\n\\n**Bu...  model_b   \n",
       "4837  На Управляющих узлах (Master Nodes) OpenShift ...  model_a   \n",
       "4838  I couldn't find any information about a church...  model_a   \n",
       "\n",
       "                           model_a                          model_b  \\\n",
       "0                   gemma-2-27b-it             gemini-1.5-flash-002   \n",
       "1                grok-2-2024-08-13               gemini-1.5-pro-002   \n",
       "2       chatgpt-4o-latest-20240903               gpt-4-0125-preview   \n",
       "3     llama-3.1-405b-instruct-bf16               reka-core-20240904   \n",
       "4                    gemma-2-9b-it                command-r-08-2024   \n",
       "...                            ...                              ...   \n",
       "4834                 gemma-2-9b-it  llama-3.1-nemotron-70b-instruct   \n",
       "4835                       o1-mini     llama-3.1-405b-instruct-bf16   \n",
       "4836                    glm-4-plus  llama-3.1-nemotron-70b-instruct   \n",
       "4837       gemini-1.5-flash-8b-001                     yi-lightning   \n",
       "4838        llama-3.1-70b-instruct            llama-3.2-3b-instruct   \n",
       "\n",
       "        language  split        source                        logits  labels  \n",
       "0        Russian  valid  current_comp     [1.4453125, -0.349609375]       0  \n",
       "1        Finnish  valid  current_comp      [0.70703125, 0.25390625]       1  \n",
       "2        English  valid  current_comp     [1.1953125, -0.138671875]       0  \n",
       "3     Vietnamese  valid  current_comp          [0.5234375, 0.34375]       0  \n",
       "4        English  valid  current_comp  [0.90234375, 0.045654296875]       0  \n",
       "...          ...    ...           ...                           ...     ...  \n",
       "4834     English  valid  current_comp          [-1.609375, 2.28125]       1  \n",
       "4835     English  valid  current_comp   [1.1015625, -0.07373046875]       0  \n",
       "4836     Chinese  valid  current_comp   [-0.1591796875, 0.94921875]       1  \n",
       "4837     unknown  valid  current_comp  [-0.0213623046875, 0.796875]       0  \n",
       "4838     English  valid  current_comp      [0.53515625, 0.47265625]       0  \n",
       "\n",
       "[4839 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/eval_data_gemma2_stage1_logits.parquet\")\n",
    "df = df.sort_values(\"id\").reset_index(drop=True)\n",
    "df[\"labels\"] = df[\"winner\"].map({\"model_a\": 0, \"model_b\": 1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7042777433353998"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_labels = df[\"labels\"].tolist()\n",
    "logits_1 = np.array(df[\"logits\"].tolist())\n",
    "accuracy_score(gt_labels, logits_1.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6951849555693325"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_parquet(\"../data/eval_data_llama3_stage1_logits.parquet\")\n",
    "df1 = df1.sort_values(\"id\").reset_index(drop=True)\n",
    "df1[\"labels\"] = df1[\"winner\"].map({\"model_a\": 0, \"model_b\": 1})\n",
    "gt_labels = df1[\"labels\"].tolist()\n",
    "logits_2 = np.array(df1[\"logits\"].tolist())\n",
    "accuracy_score(gt_labels, logits_2.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7092374457532548"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_logits = 0.8 * logits_1 + 0.2 * logits_2\n",
    "accuracy_score(gt_labels, ensemble_logits.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7092374457532548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>winner</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8b8a298a65a4169963967da44c5b05b</td>\n",
       "      <td>crie uma programa em html, js, cs,  que solici...</td>\n",
       "      <td>Aqui está um exemplo de como você pode criar u...</td>\n",
       "      <td>Aqui está um programa em HTML, JavaScript e CS...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[0.26953125, 0.78515625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6dfbc4eeb6624cdd929cabeeb6f99d26</td>\n",
       "      <td>Erzähle mir eine lustige aber lehrreiche Kurzg...</td>\n",
       "      <td>### Eine lustige und lehrreiche Kurzgeschichte...</td>\n",
       "      <td>Es war einmal ein junges, sprechendes Ferkel n...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>German</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[0.74609375, 0.6796875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7e67947c57c643be8d2d4439d97b2519</td>\n",
       "      <td>Ik wil een recept voor baklava</td>\n",
       "      <td>Hier is een basisrecept voor baklava, een klas...</td>\n",
       "      <td>Baklava is een traditionele gestoomde taart ui...</td>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.3984375, 1.6328125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d348b6c4b75747b1a6cef2d676d6e971</td>\n",
       "      <td>Сделай кратки анализ всех аэропортов Шри-Ланки...</td>\n",
       "      <td>Аэропорт \"Белгийский аэропорт\" - британский аэ...</td>\n",
       "      <td>Анализ аэропортов Шри-Ланки:\\n\\n1.  **Больница...</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>Russian</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[1.0859375, 0.322265625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e1c479a622b540b39fcff3a61822c754</td>\n",
       "      <td>Создай сайт визитку, подобного примеру (https:...</td>\n",
       "      <td>I'd be happy to help you create a website for ...</td>\n",
       "      <td>Вот код страницы и таблицы стилей, учитывающий...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Russian</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[0.10888671875, 0.87109375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125873</th>\n",
       "      <td>646ef0b0fda143cdb89cd32ed18c940c</td>\n",
       "      <td>bom dia</td>\n",
       "      <td>Bom dia!</td>\n",
       "      <td></td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>microsoft/Phi-3.5-mini-instruct</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[2.34375, -1.15625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125874</th>\n",
       "      <td>2a272049f63c4722b426a32eda916b57</td>\n",
       "      <td>测试</td>\n",
       "      <td>测试</td>\n",
       "      <td>你好。</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.1083984375, 0.98046875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125875</th>\n",
       "      <td>534e6da0e64244d4a44128f151ade350</td>\n",
       "      <td>今天</td>\n",
       "      <td>今天。</td>\n",
       "      <td>,</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[1.546875, -0.37890625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125876</th>\n",
       "      <td>f4f9ee96a26b479a99e7ddc585685c15</td>\n",
       "      <td>سلام</td>\n",
       "      <td>سلام!</td>\n",
       "      <td>خوب</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>microsoft/Phi-3-mini-4k-instruct</td>\n",
       "      <td>Persian</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[0.4609375, 0.4609375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125877</th>\n",
       "      <td>31a8c80814474ff9848d97a913c5e54f</td>\n",
       "      <td>嗯</td>\n",
       "      <td>​</td>\n",
       "      <td>😊</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.486328125, 1.34375]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125878 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0       d8b8a298a65a4169963967da44c5b05b   \n",
       "1       6dfbc4eeb6624cdd929cabeeb6f99d26   \n",
       "2       7e67947c57c643be8d2d4439d97b2519   \n",
       "3       d348b6c4b75747b1a6cef2d676d6e971   \n",
       "4       e1c479a622b540b39fcff3a61822c754   \n",
       "...                                  ...   \n",
       "125873  646ef0b0fda143cdb89cd32ed18c940c   \n",
       "125874  2a272049f63c4722b426a32eda916b57   \n",
       "125875  534e6da0e64244d4a44128f151ade350   \n",
       "125876  f4f9ee96a26b479a99e7ddc585685c15   \n",
       "125877  31a8c80814474ff9848d97a913c5e54f   \n",
       "\n",
       "                                                   prompt  \\\n",
       "0       crie uma programa em html, js, cs,  que solici...   \n",
       "1       Erzähle mir eine lustige aber lehrreiche Kurzg...   \n",
       "2                          Ik wil een recept voor baklava   \n",
       "3       Сделай кратки анализ всех аэропортов Шри-Ланки...   \n",
       "4       Создай сайт визитку, подобного примеру (https:...   \n",
       "...                                                   ...   \n",
       "125873                                            bom dia   \n",
       "125874                                                 测试   \n",
       "125875                                                 今天   \n",
       "125876                                               سلام   \n",
       "125877                                                  嗯   \n",
       "\n",
       "                                               response_a  \\\n",
       "0       Aqui está um exemplo de como você pode criar u...   \n",
       "1       ### Eine lustige und lehrreiche Kurzgeschichte...   \n",
       "2       Hier is een basisrecept voor baklava, een klas...   \n",
       "3       Аэропорт \"Белгийский аэропорт\" - британский аэ...   \n",
       "4       I'd be happy to help you create a website for ...   \n",
       "...                                                   ...   \n",
       "125873                                           Bom dia!   \n",
       "125874                                                 测试   \n",
       "125875                                                今天。   \n",
       "125876                                              سلام!   \n",
       "125877                                                  ​   \n",
       "\n",
       "                                               response_b  \\\n",
       "0       Aqui está um programa em HTML, JavaScript e CS...   \n",
       "1       Es war einmal ein junges, sprechendes Ferkel n...   \n",
       "2       Baklava is een traditionele gestoomde taart ui...   \n",
       "3       Анализ аэропортов Шри-Ланки:\\n\\n1.  **Больница...   \n",
       "4       Вот код страницы и таблицы стилей, учитывающий...   \n",
       "...                                                   ...   \n",
       "125873                                                      \n",
       "125874                                                你好。   \n",
       "125875                                                  ,   \n",
       "125876                                                خوب   \n",
       "125877                                                  😊   \n",
       "\n",
       "                                    model_a  \\\n",
       "0       meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "1                  Qwen/Qwen2.5-3B-Instruct   \n",
       "2                  Qwen/Qwen2.5-3B-Instruct   \n",
       "3                          oasst-pythia-12b   \n",
       "4       meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "...                                     ...   \n",
       "125873  meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "125874                           alpaca-13b   \n",
       "125875     meta-llama/Llama-3.1-8B-Instruct   \n",
       "125876                           chatglm-6b   \n",
       "125877                           vicuna-13b   \n",
       "\n",
       "                                     model_b    language   winner  \\\n",
       "0       mistralai/Mistral-Nemo-Instruct-2407  Portuguese  model_b   \n",
       "1                                 vicuna-13b      German  model_a   \n",
       "2                                 vicuna-13b       Dutch  model_b   \n",
       "3           meta-llama/Llama-3.1-8B-Instruct     Russian  model_a   \n",
       "4       mistralai/Mistral-Nemo-Instruct-2407     Russian  model_b   \n",
       "...                                      ...         ...      ...   \n",
       "125873       microsoft/Phi-3.5-mini-instruct  Portuguese  model_a   \n",
       "125874     meta-llama/Llama-3.1-70B-Instruct     Chinese  model_b   \n",
       "125875                        fastchat-t5-3b    Japanese  model_a   \n",
       "125876      microsoft/Phi-3-mini-4k-instruct     Persian  model_a   \n",
       "125877   meta-llama/Meta-Llama-3-8B-Instruct     Chinese  model_b   \n",
       "\n",
       "                             logits  \n",
       "0          [0.26953125, 0.78515625]  \n",
       "1           [0.74609375, 0.6796875]  \n",
       "2           [-0.3984375, 1.6328125]  \n",
       "3          [1.0859375, 0.322265625]  \n",
       "4       [0.10888671875, 0.87109375]  \n",
       "...                             ...  \n",
       "125873          [2.34375, -1.15625]  \n",
       "125874  [-0.1083984375, 0.98046875]  \n",
       "125875      [1.546875, -0.37890625]  \n",
       "125876       [0.4609375, 0.4609375]  \n",
       "125877      [-0.486328125, 1.34375]  \n",
       "\n",
       "[125878 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/lmsys1m_110k_pseudo_label_gemma2stage1.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataframe (competition train)\n",
    "# text, label (0 or 1)\n",
    "# K = 3\n",
    "# x = (1 - epsilon) * x + (epsilon / K)\n",
    "# return x\n",
    "# gemma and llama\n",
    "# +\n",
    "# pseudo label dataframe\n",
    "# text, label ([0.26953125, 0.78515625])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
