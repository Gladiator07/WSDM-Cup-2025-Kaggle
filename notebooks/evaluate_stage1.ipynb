{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>logits</th>\n",
       "      <th>logits_tta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>050475156d71ce0b29aadb791b7c2637dcc353c90bf3c2...</td>\n",
       "      <td>Consider that a very advanced and self-aware g...</td>\n",
       "      <td>Here's a detailed outline of a Python module a...</td>\n",
       "      <td>Creating a comprehensive simulation of the Orb...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.6015625, 0.58984375]</td>\n",
       "      <td>[0.4609375, 0.74609375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0741b308cee0ba4c028ffec8086fcdff01c85db230de99...</td>\n",
       "      <td>hi ! rewrite the following game and make a str...</td>\n",
       "      <td>Certainly! Below is a reworked version of the ...</td>\n",
       "      <td>Sure! Let's transform your text-based adventur...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>yi-lightning-lite</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.423828125, 0.578125]</td>\n",
       "      <td>[0.390625, 0.7734375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115888577ff36990aa7438275a4657f880673fe722eadc...</td>\n",
       "      <td>Satisfying Psychological Needs Using Luxury Br...</td>\n",
       "      <td>**Literature Review**\\n\\n**2.1. Definition of ...</td>\n",
       "      <td>Here is the literature review with a similar s...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>llama-3.1-405b-instruct-bf16</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[1.046875, 0.23828125]</td>\n",
       "      <td>[0.6953125, 0.388671875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11984059c5138393efb476c2d3feacebb45be1014e6f4c...</td>\n",
       "      <td>Title: Analyzing the Impact of Free Market Exc...</td>\n",
       "      <td>**Title**: Analyzing the Impact of Free Market...</td>\n",
       "      <td>## Analyzing the Impact of Free Market Exchang...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[2.09375, -0.71875]</td>\n",
       "      <td>[1.6328125, -0.65625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14017a37962fdc186946866a37df2abfdc4cc2a016369e...</td>\n",
       "      <td>use c++20 and make it class with oop: inline u...</td>\n",
       "      <td>Below is a refactored version of the provided ...</td>\n",
       "      <td>To convert the provided C-style code into a C+...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>chatgpt-4o-latest-20240903</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.2138671875, 0.80859375]</td>\n",
       "      <td>[0.11376953125, 1.1015625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>8fd449e93f6cfe83e15007371518a9fae37f3ffd466de9...</td>\n",
       "      <td>–ò–∏ –ø—Ä–∏–≤–µ—Ç–∏–∫</td>\n",
       "      <td>–ü—Ä–∏–≤–µ—Ç!  –ö–∞–∫ –¥–µ–ª–∞?</td>\n",
       "      <td>–ü—Ä–∏–≤–µ—Ç–∏–∫! –ö–∞–∫ —è –º–æ–≥—É –ø–æ–º–æ—á—å —Ç–µ–±–µ —Å–µ–≥–æ–¥–Ω—è? üòäü§ñ</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-flash-8b-001</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>Russian</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[-0.1689453125, 0.93359375]</td>\n",
       "      <td>[0.49609375, 0.388671875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>58fac0d8d980831df3a09a46aa070a7c99e3ef6864b9ff...</td>\n",
       "      <td>How can I found out the solution to the world?...</td>\n",
       "      <td>Unanswerable.</td>\n",
       "      <td>Research</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>grok-2-2024-08-13</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.69921875, 0.4140625]</td>\n",
       "      <td>[0.60546875, 0.251953125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>d62c05368101623351bb2b9bf09934f94852dceb60acdd...</td>\n",
       "      <td>How can I found out the solution to the world?...</td>\n",
       "      <td>Reflection.</td>\n",
       "      <td>Collaboration.</td>\n",
       "      <td>model_a</td>\n",
       "      <td>yi-lightning</td>\n",
       "      <td>command-r-08-2024</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.154296875, 0.734375]</td>\n",
       "      <td>[0.59375, 0.318359375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>17f18300faa205116513ae2310cc4f5f60fe3d970148e6...</td>\n",
       "      <td>eae</td>\n",
       "      <td>Eae! Como posso ajudar voc√™ hoje?</td>\n",
       "      <td>Eae! Como t√°?</td>\n",
       "      <td>model_b</td>\n",
       "      <td>qwen-plus-0828</td>\n",
       "      <td>chatgpt-4o-latest-20240903</td>\n",
       "      <td>Basque</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.32421875, 0.55078125]</td>\n",
       "      <td>[0.70703125, 0.076171875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>a0b4c1a67c8e73a57ef2c3d65fb06264b6f99ff0d72fa4...</td>\n",
       "      <td>translate to Chinese: Guideline Transaction Me...</td>\n",
       "      <td>ÊåáÂØº‰∫§ÊòìÊ≥ï</td>\n",
       "      <td>ÊåáÂºï‰∫§ÊòìÊñπÊ≥ï</td>\n",
       "      <td>model_b</td>\n",
       "      <td>qwen-plus-0828</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.90234375, 0.216796875]</td>\n",
       "      <td>[0.921875, -0.0849609375]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4839 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     050475156d71ce0b29aadb791b7c2637dcc353c90bf3c2...   \n",
       "1     0741b308cee0ba4c028ffec8086fcdff01c85db230de99...   \n",
       "2     115888577ff36990aa7438275a4657f880673fe722eadc...   \n",
       "3     11984059c5138393efb476c2d3feacebb45be1014e6f4c...   \n",
       "4     14017a37962fdc186946866a37df2abfdc4cc2a016369e...   \n",
       "...                                                 ...   \n",
       "4834  8fd449e93f6cfe83e15007371518a9fae37f3ffd466de9...   \n",
       "4835  58fac0d8d980831df3a09a46aa070a7c99e3ef6864b9ff...   \n",
       "4836  d62c05368101623351bb2b9bf09934f94852dceb60acdd...   \n",
       "4837  17f18300faa205116513ae2310cc4f5f60fe3d970148e6...   \n",
       "4838  a0b4c1a67c8e73a57ef2c3d65fb06264b6f99ff0d72fa4...   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     Consider that a very advanced and self-aware g...   \n",
       "1     hi ! rewrite the following game and make a str...   \n",
       "2     Satisfying Psychological Needs Using Luxury Br...   \n",
       "3     Title: Analyzing the Impact of Free Market Exc...   \n",
       "4     use c++20 and make it class with oop: inline u...   \n",
       "...                                                 ...   \n",
       "4834                                       –ò–∏ –ø—Ä–∏–≤–µ—Ç–∏–∫    \n",
       "4835  How can I found out the solution to the world?...   \n",
       "4836  How can I found out the solution to the world?...   \n",
       "4837                                                eae   \n",
       "4838  translate to Chinese: Guideline Transaction Me...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0     Here's a detailed outline of a Python module a...   \n",
       "1     Certainly! Below is a reworked version of the ...   \n",
       "2     **Literature Review**\\n\\n**2.1. Definition of ...   \n",
       "3     **Title**: Analyzing the Impact of Free Market...   \n",
       "4     Below is a refactored version of the provided ...   \n",
       "...                                                 ...   \n",
       "4834                                 –ü—Ä–∏–≤–µ—Ç!  –ö–∞–∫ –¥–µ–ª–∞?   \n",
       "4835                                      Unanswerable.   \n",
       "4836                                        Reflection.   \n",
       "4837                  Eae! Como posso ajudar voc√™ hoje?   \n",
       "4838                                              ÊåáÂØº‰∫§ÊòìÊ≥ï   \n",
       "\n",
       "                                             response_b   winner  \\\n",
       "0     Creating a comprehensive simulation of the Orb...  model_b   \n",
       "1     Sure! Let's transform your text-based adventur...  model_b   \n",
       "2     Here is the literature review with a similar s...  model_b   \n",
       "3     ## Analyzing the Impact of Free Market Exchang...  model_a   \n",
       "4     To convert the provided C-style code into a C+...  model_b   \n",
       "...                                                 ...      ...   \n",
       "4834       –ü—Ä–∏–≤–µ—Ç–∏–∫! –ö–∞–∫ —è –º–æ–≥—É –ø–æ–º–æ—á—å —Ç–µ–±–µ —Å–µ–≥–æ–¥–Ω—è? üòäü§ñ  model_a   \n",
       "4835                                           Research  model_b   \n",
       "4836                                     Collaboration.  model_a   \n",
       "4837                                      Eae! Como t√°?  model_b   \n",
       "4838                                             ÊåáÂºï‰∫§ÊòìÊñπÊ≥ï  model_b   \n",
       "\n",
       "                      model_a                       model_b language  split  \\\n",
       "0      claude-3-opus-20240229        gpt-4o-mini-2024-07-18  English  valid   \n",
       "1           yi-lightning-lite                       o1-mini  English  valid   \n",
       "2          reka-core-20240904  llama-3.1-405b-instruct-bf16  English  valid   \n",
       "3                  o1-preview                 gemma-2-2b-it  English  valid   \n",
       "4       llama-3.2-3b-instruct    chatgpt-4o-latest-20240903  English  valid   \n",
       "...                       ...                           ...      ...    ...   \n",
       "4834  gemini-1.5-flash-8b-001                    glm-4-plus  Russian  valid   \n",
       "4835       gemini-1.5-pro-002             grok-2-2024-08-13  English  valid   \n",
       "4836             yi-lightning             command-r-08-2024  English  valid   \n",
       "4837           qwen-plus-0828    chatgpt-4o-latest-20240903   Basque  valid   \n",
       "4838           qwen-plus-0828                    glm-4-plus  English  valid   \n",
       "\n",
       "            source                       logits                  logits_tta  \n",
       "0     current_comp      [0.6015625, 0.58984375]     [0.4609375, 0.74609375]  \n",
       "1     current_comp      [0.423828125, 0.578125]       [0.390625, 0.7734375]  \n",
       "2     current_comp       [1.046875, 0.23828125]    [0.6953125, 0.388671875]  \n",
       "3     current_comp          [2.09375, -0.71875]       [1.6328125, -0.65625]  \n",
       "4     current_comp   [0.2138671875, 0.80859375]  [0.11376953125, 1.1015625]  \n",
       "...            ...                          ...                         ...  \n",
       "4834  current_comp  [-0.1689453125, 0.93359375]   [0.49609375, 0.388671875]  \n",
       "4835  current_comp      [0.69921875, 0.4140625]   [0.60546875, 0.251953125]  \n",
       "4836  current_comp      [0.154296875, 0.734375]      [0.59375, 0.318359375]  \n",
       "4837  current_comp     [0.32421875, 0.55078125]   [0.70703125, 0.076171875]  \n",
       "4838  current_comp    [0.90234375, 0.216796875]   [0.921875, -0.0849609375]  \n",
       "\n",
       "[4839 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = pd.read_parquet(\"../data/eval_data_gemma2_stage1_logits.parquet\")\n",
    "gtta_df = pd.read_parquet(\"../data/eval_data_gemma2_stage1_logits_tta.parquet\")\n",
    "\n",
    "cols = [\"id\", \"prompt\", \"response_a\", \"response_b\", \"response_b\", \"model_a\", \"model_b\", \"language\", \"split\", \"source\", \"winner\"]\n",
    "gmerged_df = pd.merge(gdf, gtta_df, on=cols, suffixes=(\"\", \"_tta\"))\n",
    "gmerged_df['logits_tta'] = gmerged_df['logits_tta'].apply(lambda x: x[::-1])\n",
    "gmerged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707997520148791"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 0.6\n",
    "gemma_logits = w * np.array(gmerged_df['logits'].tolist()) + (1 - w) * np.array(gmerged_df['logits_tta'].tolist())\n",
    "gemma_preds = np.argmax(gemma_logits, axis=-1)\n",
    "ground_truth = gmerged_df['winner'].map({\"model_a\": 0, \"model_b\": 1}).values\n",
    "gemma_acc = accuracy_score(ground_truth, gemma_preds)\n",
    "gemma_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>source</th>\n",
       "      <th>logits</th>\n",
       "      <th>logits_tta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115888577ff36990aa7438275a4657f880673fe722eadc...</td>\n",
       "      <td>Satisfying Psychological Needs Using Luxury Br...</td>\n",
       "      <td>**Literature Review**\\n\\n**2.1. Definition of ...</td>\n",
       "      <td>Here is the literature review with a similar s...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>llama-3.1-405b-instruct-bf16</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[0.76953125, 0.369140625]</td>\n",
       "      <td>[1.0703125, 0.11474609375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11984059c5138393efb476c2d3feacebb45be1014e6f4c...</td>\n",
       "      <td>Title: Analyzing the Impact of Free Market Exc...</td>\n",
       "      <td>**Title**: Analyzing the Impact of Free Market...</td>\n",
       "      <td>## Analyzing the Impact of Free Market Exchang...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>English</td>\n",
       "      <td>valid</td>\n",
       "      <td>current_comp</td>\n",
       "      <td>[2.46875, -0.71875]</td>\n",
       "      <td>[2.890625, -1.0703125]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  115888577ff36990aa7438275a4657f880673fe722eadc...   \n",
       "1  11984059c5138393efb476c2d3feacebb45be1014e6f4c...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Satisfying Psychological Needs Using Luxury Br...   \n",
       "1  Title: Analyzing the Impact of Free Market Exc...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  **Literature Review**\\n\\n**2.1. Definition of ...   \n",
       "1  **Title**: Analyzing the Impact of Free Market...   \n",
       "\n",
       "                                          response_b   winner  \\\n",
       "0  Here is the literature review with a similar s...  model_b   \n",
       "1  ## Analyzing the Impact of Free Market Exchang...  model_a   \n",
       "\n",
       "              model_a                       model_b language  split  \\\n",
       "0  reka-core-20240904  llama-3.1-405b-instruct-bf16  English  valid   \n",
       "1          o1-preview                 gemma-2-2b-it  English  valid   \n",
       "\n",
       "         source                     logits                  logits_tta  \n",
       "0  current_comp  [0.76953125, 0.369140625]  [1.0703125, 0.11474609375]  \n",
       "1  current_comp        [2.46875, -0.71875]      [2.890625, -1.0703125]  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf = pd.read_parquet(\"../data/eval_data_llama3_stage1_logits.parquet\")\n",
    "ltta_df = pd.read_parquet(\"../data/eval_data_llama3_stage1_logits_tta.parquet\")\n",
    "\n",
    "cols = [\"id\", \"prompt\", \"response_a\", \"response_b\", \"response_b\", \"model_a\", \"model_b\", \"language\", \"split\", \"source\", \"winner\"]\n",
    "lmerged_df = pd.merge(ldf, ltta_df, on=cols, suffixes=(\"\", \"_tta\"))\n",
    "lmerged_df['logits_tta'] = lmerged_df['logits_tta'].apply(lambda x: x[::-1])\n",
    "lmerged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_logits = 0.5 * np.array(lmerged_df['logits'].tolist()) + 0.5 * np.array(lmerged_df['logits_tta'].tolist())\n",
    "llama_preds = np.argmax(llama_logits, axis=-1)\n",
    "ground_truth = lmerged_df['winner'].map({\"model_a\": 0, \"model_b\": 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6997313494523661"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_acc = accuracy_score(ground_truth, llama_preds)\n",
    "llama_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge gemma and llama\n",
    "merged_df = pd.merge(gmerged_df, lmerged_df, on=cols, suffixes=(\"_gemma\", \"_llama\"))\n",
    "merged_df[\"logits_e_gemma\"] = ((np.array(merged_df[\"logits_gemma\"].tolist()) + np.array(merged_df[\"logits_tta_gemma\"].tolist())) / 2).tolist()\n",
    "merged_df[\"logits_e_llama\"] = ((np.array(merged_df[\"logits_llama\"].tolist()) + np.array(merged_df[\"logits_tta_llama\"].tolist())) / 2).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best weights\n",
    "best_acc = 0\n",
    "best_weights = None\n",
    "for w in np.linspace(0, 1, 100):\n",
    "    ensemble_logits = w * np.array(merged_df[\"logits_e_gemma\"].tolist()) + (1 - w) * np.array(merged_df[\"logits_e_llama\"].tolist())\n",
    "    ensemble_preds = np.argmax(ensemble_logits, axis=-1)\n",
    "    acc = accuracy_score(ground_truth, ensemble_preds)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_weights = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7108906798925397, 0.787878787878788)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7108906798925397"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 0.7878\n",
    "ensemble_logits = w * np.array(merged_df[\"logits_e_gemma\"].tolist()) + (1 - w) * np.array(merged_df[\"logits_e_llama\"].tolist())\n",
    "ensemble_preds = np.argmax(ensemble_logits, axis=-1)\n",
    "accuracy_score(ground_truth, ensemble_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>winner</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>0000c48f341d489591e3bbeca1821926</td>\n",
       "      <td>¬øC√≥mo hago una petici√≥n Ajax en django con jQu...</td>\n",
       "      <td>Para hacer una petici√≥n Ajax en Django con jQu...</td>\n",
       "      <td>¬°Hola! ¬°Claro que s√≠! Aqu√≠ te puedo ayudar con...</td>\n",
       "      <td>Qwen/Qwen2-1.5B-Instruct</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.06689453125, 0.87109375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109937</th>\n",
       "      <td>0000ce95d8dd4aa6bca0e792b767d550</td>\n",
       "      <td>‰Ω†Â•Ω</td>\n",
       "      <td>‰Ω†Â•ΩÔºÅÊúâ‰ªÄ‰πàÊàëËÉΩ‰∏∫‰Ω†ÊïàÂä≥ÁöÑÂêóÔºü</td>\n",
       "      <td>Hello! How can I help you today? If you have a...</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[1.0390625, 0.0771484375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120267</th>\n",
       "      <td>000174aa3722401cae71c6b3197a82e0</td>\n",
       "      <td>‰Ω†Â•Ω</td>\n",
       "      <td>‰Ω†Â•ΩÔºÅÊàëÊòØ‰∏≠ÊñáËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇÂ¶Ç‰ΩïÂèØ‰ª•Âπ´Âä©‰Ω†Ôºü</td>\n",
       "      <td>‰Ω†Â•ΩÔºÅÊúâ‰ªÄ‰πàÊàëËÉΩÂ∏ÆÂä©‰Ω†ÁöÑÂêóÔºü</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[0.09130859375, 0.73828125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85320</th>\n",
       "      <td>0001c758568b4baba4b84389679fbe85</td>\n",
       "      <td>–ü—Ä–∏–≤–µ—Ç</td>\n",
       "      <td>–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–∫–∞–∂–∏—Ç–µ, –∫–∞–∫ –º–æ–≥—É –ø–æ...</td>\n",
       "      <td>–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —è –º–æ–≥—É –í–∞–º –ø–æ–º–æ—á—å?</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Russian</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[0.04248046875, 0.828125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119159</th>\n",
       "      <td>00026c3ac57b47e7bf4e4c0ac81c8082</td>\n",
       "      <td>hi</td>\n",
       "      <td>Hello! How can I help you today?</td>\n",
       "      <td>Hello! üëã  How can I help you today? üòä</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>unknown</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[0.1015625, 0.67578125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103045</th>\n",
       "      <td>fffe559651f241bdb473eb396ccdf042</td>\n",
       "      <td>zxcvzxcv</td>\n",
       "      <td>It seems like you're typing some random charac...</td>\n",
       "      <td>I'm sorry, I don't understand what you are try...</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Danish</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[0.671875, 0.365234375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106644</th>\n",
       "      <td>fffe80dc4e37411fa4355236f52bcd07</td>\n",
       "      <td>Hiya</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! How can I help you today? If you have a...</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>Nexusflow/Starling-LM-7B-beta</td>\n",
       "      <td>Waray</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[0.373046875, 0.48046875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114954</th>\n",
       "      <td>fffed7463ef64edaac3d247ad0d0918b</td>\n",
       "      <td>‰Ω†Â•Ω</td>\n",
       "      <td>‰Ω†Â•ΩÔºÅÊúâ‰ªÄ‰πàÊàëËÉΩ‰∏∫‰Ω†ÊïàÂä≥ÁöÑÂêóÔºü</td>\n",
       "      <td>Ni hao! Kamusta! Hello! How can I help you to...</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>mistralai/Mixtral-8x7B-Instruct-v0.1</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[1.171875, -0.07373046875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29808</th>\n",
       "      <td>ffff3da3bc7f4493b93b370bc0bab73e</td>\n",
       "      <td>I have submitted a paper on the topic of trust...</td>\n",
       "      <td>Dear Reviewers,\\n\\nThank you for your valuable...</td>\n",
       "      <td>In response to the question about the meaning ...</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>Nexusflow/Starling-LM-7B-beta</td>\n",
       "      <td>unknown</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[0.71875, 0.234375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96506</th>\n",
       "      <td>fffff4a6407e4bf9a231cfbb4f37f441</td>\n",
       "      <td>Quem ganhou a copa de 2022?</td>\n",
       "      <td>Desculpe, mas eu n√£o tenho informa√ß√µes sobre u...</td>\n",
       "      <td>A resposta √© que ainda n√£o foi definido qual t...</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.0595703125, 1.0390625]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125878 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "2046    0000c48f341d489591e3bbeca1821926   \n",
       "109937  0000ce95d8dd4aa6bca0e792b767d550   \n",
       "120267  000174aa3722401cae71c6b3197a82e0   \n",
       "85320   0001c758568b4baba4b84389679fbe85   \n",
       "119159  00026c3ac57b47e7bf4e4c0ac81c8082   \n",
       "...                                  ...   \n",
       "103045  fffe559651f241bdb473eb396ccdf042   \n",
       "106644  fffe80dc4e37411fa4355236f52bcd07   \n",
       "114954  fffed7463ef64edaac3d247ad0d0918b   \n",
       "29808   ffff3da3bc7f4493b93b370bc0bab73e   \n",
       "96506   fffff4a6407e4bf9a231cfbb4f37f441   \n",
       "\n",
       "                                                   prompt  \\\n",
       "2046    ¬øC√≥mo hago una petici√≥n Ajax en django con jQu...   \n",
       "109937                                                 ‰Ω†Â•Ω   \n",
       "120267                                                 ‰Ω†Â•Ω   \n",
       "85320                                              –ü—Ä–∏–≤–µ—Ç   \n",
       "119159                                                 hi   \n",
       "...                                                   ...   \n",
       "103045                                           zxcvzxcv   \n",
       "106644                                               Hiya   \n",
       "114954                                                 ‰Ω†Â•Ω   \n",
       "29808   I have submitted a paper on the topic of trust...   \n",
       "96506                         Quem ganhou a copa de 2022?   \n",
       "\n",
       "                                               response_a  \\\n",
       "2046    Para hacer una petici√≥n Ajax en Django con jQu...   \n",
       "109937                                    ‰Ω†Â•ΩÔºÅÊúâ‰ªÄ‰πàÊàëËÉΩ‰∏∫‰Ω†ÊïàÂä≥ÁöÑÂêóÔºü   \n",
       "120267                              ‰Ω†Â•ΩÔºÅÊàëÊòØ‰∏≠ÊñáËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇÂ¶Ç‰ΩïÂèØ‰ª•Âπ´Âä©‰Ω†Ôºü   \n",
       "85320   –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–∫–∞–∂–∏—Ç–µ, –∫–∞–∫ –º–æ–≥—É –ø–æ...   \n",
       "119159                   Hello! How can I help you today?   \n",
       "...                                                   ...   \n",
       "103045  It seems like you're typing some random charac...   \n",
       "106644                 Hello! How can I assist you today?   \n",
       "114954                                    ‰Ω†Â•ΩÔºÅÊúâ‰ªÄ‰πàÊàëËÉΩ‰∏∫‰Ω†ÊïàÂä≥ÁöÑÂêóÔºü   \n",
       "29808   Dear Reviewers,\\n\\nThank you for your valuable...   \n",
       "96506   Desculpe, mas eu n√£o tenho informa√ß√µes sobre u...   \n",
       "\n",
       "                                               response_b  \\\n",
       "2046    ¬°Hola! ¬°Claro que s√≠! Aqu√≠ te puedo ayudar con...   \n",
       "109937  Hello! How can I help you today? If you have a...   \n",
       "120267                                     ‰Ω†Â•ΩÔºÅÊúâ‰ªÄ‰πàÊàëËÉΩÂ∏ÆÂä©‰Ω†ÁöÑÂêóÔºü   \n",
       "85320                      –ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —è –º–æ–≥—É –í–∞–º –ø–æ–º–æ—á—å?   \n",
       "119159              Hello! üëã  How can I help you today? üòä   \n",
       "...                                                   ...   \n",
       "103045  I'm sorry, I don't understand what you are try...   \n",
       "106644  Hello! How can I help you today? If you have a...   \n",
       "114954   Ni hao! Kamusta! Hello! How can I help you to...   \n",
       "29808   In response to the question about the meaning ...   \n",
       "96506   A resposta √© que ainda n√£o foi definido qual t...   \n",
       "\n",
       "                                   model_a  \\\n",
       "2046              Qwen/Qwen2-1.5B-Instruct   \n",
       "109937                          vicuna-13b   \n",
       "120267    meta-llama/Llama-3.1-8B-Instruct   \n",
       "85320   mistralai/Mistral-7B-Instruct-v0.2   \n",
       "119159                          vicuna-13b   \n",
       "...                                    ...   \n",
       "103045    meta-llama/Llama-3.2-3B-Instruct   \n",
       "106644                          chatglm-6b   \n",
       "114954                          vicuna-13b   \n",
       "29808                           vicuna-33b   \n",
       "96506                           vicuna-13b   \n",
       "\n",
       "                                     model_b    language   winner  \\\n",
       "2046                        llama-2-13b-chat     Spanish  model_b   \n",
       "109937    mistralai/Mistral-7B-Instruct-v0.3     Chinese  model_a   \n",
       "120267                            vicuna-13b     Chinese  model_b   \n",
       "85320                             vicuna-13b     Russian  model_b   \n",
       "119159                  google/gemma-2-9b-it     unknown  model_b   \n",
       "...                                      ...         ...      ...   \n",
       "103045                         gpt-3.5-turbo      Danish  model_a   \n",
       "106644         Nexusflow/Starling-LM-7B-beta       Waray  model_b   \n",
       "114954  mistralai/Mixtral-8x7B-Instruct-v0.1     Chinese  model_a   \n",
       "29808          Nexusflow/Starling-LM-7B-beta     unknown  model_a   \n",
       "96506     mistralai/Mistral-7B-Instruct-v0.3  Portuguese  model_b   \n",
       "\n",
       "                              logits  \n",
       "2046    [-0.06689453125, 0.87109375]  \n",
       "109937     [1.0390625, 0.0771484375]  \n",
       "120267   [0.09130859375, 0.73828125]  \n",
       "85320      [0.04248046875, 0.828125]  \n",
       "119159       [0.1015625, 0.67578125]  \n",
       "...                              ...  \n",
       "103045       [0.671875, 0.365234375]  \n",
       "106644     [0.373046875, 0.48046875]  \n",
       "114954    [1.171875, -0.07373046875]  \n",
       "29808            [0.71875, 0.234375]  \n",
       "96506     [-0.0595703125, 1.0390625]  \n",
       "\n",
       "[125878 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure tta works correctly\n",
    "df = pd.read_parquet(\"../data/lmsys1m_125k_pseudo_label_gemma2stage1.parquet\").sort_values(\"id\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>winner</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>000c42ef0246417283d9826d4ffd9f57</td>\n",
       "      <td>Á¥†‰∫∫„Åå„Çπ„Éä„ÉÉ„ÇØ„ÇíÂßã„ÇÅ„Å¶Ë®≠„Åë„Çã„Å´„ÅØ</td>\n",
       "      <td>Á¥†‰∫∫„ÅØ„Çπ„Éä„ÉÉ„ÇØ„ÇíÂßã„ÇÅ„ÇãÂâç„Å´Ë®≠„Åë„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ „Åù„ÅÆË®≠ÂÆö„ÅØÂΩºÂ•≥„ÅÆÂßøÂã¢„ÄÅÂßøÂã¢„ÅÆÂõ∫Êúâ„Å™„É©„Ç§„ÉÜ„Ç£„É≥„Ç∞...</td>\n",
       "      <td>A great topic! üçø Starting a snack business as ...</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-0.98828125, 2.125]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id            prompt  \\\n",
       "1239  000c42ef0246417283d9826d4ffd9f57  Á¥†‰∫∫„Åå„Çπ„Éä„ÉÉ„ÇØ„ÇíÂßã„ÇÅ„Å¶Ë®≠„Åë„Çã„Å´„ÅØ   \n",
       "\n",
       "                                             response_a  \\\n",
       "1239  Á¥†‰∫∫„ÅØ„Çπ„Éä„ÉÉ„ÇØ„ÇíÂßã„ÇÅ„ÇãÂâç„Å´Ë®≠„Åë„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ „Åù„ÅÆË®≠ÂÆö„ÅØÂΩºÂ•≥„ÅÆÂßøÂã¢„ÄÅÂßøÂã¢„ÅÆÂõ∫Êúâ„Å™„É©„Ç§„ÉÜ„Ç£„É≥„Ç∞...   \n",
       "\n",
       "                                             response_b     model_a  \\\n",
       "1239  A great topic! üçø Starting a snack business as ...  alpaca-13b   \n",
       "\n",
       "                                  model_b  language   winner  \\\n",
       "1239  meta-llama/Meta-Llama-3-8B-Instruct  Japanese  model_b   \n",
       "\n",
       "                    logits  \n",
       "1239  [-0.98828125, 2.125]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tta = pd.read_parquet(\"../data/lmsys1m_125k_pseudo_label_gemma2stage1_tta.parquet\").sort_values(\"id\")\n",
    "df_tta[df_tta[\"id\"] == \"000c42ef0246417283d9826d4ffd9f57\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>winner</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31557</th>\n",
       "      <td>000c42ef0246417283d9826d4ffd9f57</td>\n",
       "      <td>Á¥†‰∫∫„Åå„Çπ„Éä„ÉÉ„ÇØ„ÇíÂßã„ÇÅ„Å¶Ë®≠„Åë„Çã„Å´„ÅØ</td>\n",
       "      <td>Á¥†‰∫∫„ÅØ„Çπ„Éä„ÉÉ„ÇØ„ÇíÂßã„ÇÅ„ÇãÂâç„Å´Ë®≠„Åë„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ „Åù„ÅÆË®≠ÂÆö„ÅØÂΩºÂ•≥„ÅÆÂßøÂã¢„ÄÅÂßøÂã¢„ÅÆÂõ∫Êúâ„Å™„É©„Ç§„ÉÜ„Ç£„É≥„Ç∞...</td>\n",
       "      <td>A great topic! üçø Starting a snack business as ...</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[-1.1953125, 2.140625]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id            prompt  \\\n",
       "31557  000c42ef0246417283d9826d4ffd9f57  Á¥†‰∫∫„Åå„Çπ„Éä„ÉÉ„ÇØ„ÇíÂßã„ÇÅ„Å¶Ë®≠„Åë„Çã„Å´„ÅØ   \n",
       "\n",
       "                                              response_a  \\\n",
       "31557  Á¥†‰∫∫„ÅØ„Çπ„Éä„ÉÉ„ÇØ„ÇíÂßã„ÇÅ„ÇãÂâç„Å´Ë®≠„Åë„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ „Åù„ÅÆË®≠ÂÆö„ÅØÂΩºÂ•≥„ÅÆÂßøÂã¢„ÄÅÂßøÂã¢„ÅÆÂõ∫Êúâ„Å™„É©„Ç§„ÉÜ„Ç£„É≥„Ç∞...   \n",
       "\n",
       "                                              response_b     model_a  \\\n",
       "31557  A great topic! üçø Starting a snack business as ...  alpaca-13b   \n",
       "\n",
       "                                   model_b  language   winner  \\\n",
       "31557  meta-llama/Meta-Llama-3-8B-Instruct  Japanese  model_b   \n",
       "\n",
       "                       logits  \n",
       "31557  [-1.1953125, 2.140625]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"id\"] == \"000c42ef0246417283d9826d4ffd9f57\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
